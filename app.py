import streamlit as st
import pandas as pd
import mysql.connector
from mysql.connector import Error
import os
from datetime import datetime
import time
import base64
from functools import lru_cache
import threading
from concurrent.futures import ThreadPoolExecutor
from io import BytesIO  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï pointer ‡πÅ‡∏•‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô bytes


                
# Import modules with error handling
try:
    from database import DatabaseManager
except ImportError as e:
    st.error(f"Cannot import DatabaseManager: {e}")
    st.stop()

try:
    from file_processor import FileProcessor
except ImportError as e:
    st.error(f"Cannot import FileProcessor: {e}")
    st.stop()

# Configure page
st.set_page_config(
    page_title="Database Management Hub",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)
 

st.markdown("""
<style>
/* ===== Global Styling ===== */
html, body, [class*="stAppViewContainer"] {
    font-family: 'Sarabun', sans-serif !important;
    color: #222;
}
[data-testid="stSidebar"] {
    background: linear-gradient(180deg,#f9fafc 0%,#eef1f9 100%);
    border-right: 1px solid #e0e0e0;
    padding: 1.2rem;
}
[data-testid="stSidebar"] h3, [data-testid="stSidebar"] h4 {
    color: #3b3b98;
}
button[kind="primary"] {
    border-radius: 10px !important;
}
.status-success {
    background:#e6f4ea;
    color:#137333;
    padding:6px 10px;
    border-radius:6px;
}
.status-error {
    background:#fce8e6;
    color:#c5221f;
    padding:6px 10px;
    border-radius:6px;
}
</style>
""", unsafe_allow_html=True)

# ---- session defaults (safe) ----
for k, v in {
    'favorites': [],
    'loaded_procedures': [],
    'last_proc_filter': "",
    'last_proc_exact': False,
    'execution_history': [],
    # event flags
    'PROC_RUN_EVENT': None,       # {'name': str, 'params': list|None}
    'PROC_ADD_FAV_EVENT': None,   # {'name': str}
}.items():
    st.session_state.setdefault(k, v)
 

# ===== CACHING FUNCTIONS =====
@st.cache_data(ttl=300)
def get_cached_tables_info():
    try:
        db_manager = DatabaseManager()
        return db_manager.get_tables_with_info()
    except Exception as e:
        st.error(f"Error getting tables info: {e}")
        return []

@st.cache_data(ttl=300)
def get_cached_table_columns(table_name):
    try:
        db_manager = DatabaseManager()
        return db_manager.get_table_columns(table_name)
    except Exception as e:
        return []

@st.cache_data(ttl=60)
def get_cached_table_preview(table_name, limit=5):
    try:
        if 'db_manager' in st.session_state:
            return st.session_state.db_manager.get_table_preview(table_name, limit)
    except Exception as e:
        st.error(f"Preview error: {str(e)}")
    # fallback
    try:
        db_manager = DatabaseManager()
        return db_manager.get_table_preview(table_name, limit)
    except Exception:
        return pd.DataFrame()

# ---------- Stored procedures (filter/load) ----------
@st.cache_data(ttl=300)
def get_stored_procedures(name_filter: str = "", limit: int = 50):
    """Get list of stored procedures from database with optional wildcard filter and limit"""
    try:
        db_manager = DatabaseManager()
        base_sql = """
        SELECT 
            ROUTINE_NAME,
            ROUTINE_TYPE,
            DTD_IDENTIFIER as RETURNS,
            CREATED,
            LAST_ALTERED,
            ROUTINE_COMMENT
        FROM INFORMATION_SCHEMA.ROUTINES
        WHERE ROUTINE_SCHEMA = %s
        """
        params = [db_manager.connection_config['database']]
        # üîπ Smart search: auto add wildcard if user doesn't type it
        if name_filter and '%' not in name_filter:
            name_filter = f"%{name_filter}%"
        base_sql += " AND ROUTINE_NAME LIKE %s"
        params.append(name_filter if name_filter else "%")
        base_sql += " ORDER BY ROUTINE_NAME LIMIT %s"
        params.append(limit)
        df = db_manager.execute_query(base_sql, tuple(params))
        return df.to_dict('records') if (df is not None and not df.empty) else []
    except Exception as e:
        st.error(f"Error getting procedures: {e}")
        return []

def get_procedure_parameters(procedure_name):
    """Get parameters for a stored procedure"""
    try:
        db_manager = DatabaseManager()
        query = """
        SELECT 
            PARAMETER_NAME,
            PARAMETER_MODE,
            DATA_TYPE,
            CHARACTER_MAXIMUM_LENGTH,
            NUMERIC_PRECISION
        FROM INFORMATION_SCHEMA.PARAMETERS
        WHERE SPECIFIC_SCHEMA = %s 
        AND SPECIFIC_NAME = %s
        AND PARAMETER_NAME IS NOT NULL
        ORDER BY ORDINAL_POSITION
        """
        df = db_manager.execute_query(query, (db_manager.connection_config['database'], procedure_name))
        return df.to_dict('records') if (df is not None and not df.empty) else []
    except Exception as e:
        st.error(f"Error getting parameters: {e}")
        return []

def execute_procedure(procedure_name, parameters=None):
    """Original execute (kept, not used by the new UI flow but preserved to not break other logic)"""
    conn = None
    cursor = None
    results = []
    try:
        db_manager = DatabaseManager()
        conn = mysql.connector.connect(
            host=db_manager.connection_config['host'],
            port=db_manager.connection_config.get('port', 3306),
            database=db_manager.connection_config['database'],
            user=db_manager.connection_config['user'],
            password=db_manager.connection_config['password'],
            charset=db_manager.connection_config.get('charset', 'utf8mb4'),
            autocommit=False,
            connection_timeout=10,
        )
        cursor = conn.cursor(buffered=True, dictionary=True)
        args = parameters if parameters is not None else []
        cursor.callproc(procedure_name, args)
        for rs in cursor.stored_results():
            rows = rs.fetchall()
            results.append(rows)
        try:
            while cursor.nextset():
                pass
        except mysql.connector.Error:
            pass
        conn.commit()
        return {'success': True,'message': f'Procedure {procedure_name} executed successfully','results': results}
    except mysql.connector.Error as e:
        if conn:
            try: conn.rollback()
            except Exception: pass
        return {
            'success': False,
            'error': str(e),
            'error_details': {
                'errno': getattr(e, 'errno', None),
                'sqlstate': getattr(e, 'sqlstate', None),
                'msg': getattr(e, 'msg', str(e))
            }
        }
    except Exception as e:
        if conn:
            try: conn.rollback()
            except Exception: pass
        return {'success': False, 'error': str(e)}
    finally:
        try:
            if cursor: cursor.close()
        except Exception: pass
        try:
            if conn: conn.close()
        except Exception: pass

# ---------- NEW: execute with visible progress ----------
def execute_procedure_with_progress(procedure_name, parameters=None, fetch_chunk=1000):
    conn = None
    cursor = None
    results = []
    progress = st.progress(0)
    status = st.empty()
    try:
        status.info("Connecting to database...")
        progress.progress(5)
        db_manager = DatabaseManager()
        conn = mysql.connector.connect(
            host=db_manager.connection_config['host'],
            port=db_manager.connection_config.get('port', 3306),
            database=db_manager.connection_config['database'],
            user=db_manager.connection_config['user'],
            password=db_manager.connection_config['password'],
            charset=db_manager.connection_config.get('charset', 'utf8mb4'),
            autocommit=False,
            connection_timeout=10,
        )
        cursor = conn.cursor(buffered=True, dictionary=True)
        status.info(f"Calling procedure: {procedure_name}")
        progress.progress(15)
        args = parameters if parameters is not None else []
        cursor.callproc(procedure_name, args)
        stage_end  = 90
        # fetch result sets
        for rs in cursor.stored_results():
            status.info("Fetching result set...")
            rows_acc = []
            while True:
                rows = rs.fetchmany(size=fetch_chunk)
                if not rows:
                    break
                rows_acc.extend(rows)
                progress.progress(min(stage_end, progress_value_bump(step=5)))
            results.append(rows_acc)
        # clear pending sets (ok packets)
        try:
            while cursor.nextset():
                pass
        except mysql.connector.Error:
            pass
        status.info("Committing transaction...")
        progress.progress(95)
        conn.commit()
        progress.progress(100)
        status.success(f"Commit done.")
        return {'success': True,'message': f'Procedure {procedure_name} executed successfully','results': results}
    except mysql.connector.Error as e:
        if conn:
            try: conn.rollback()
            except Exception: pass
        status.error(f"MySQL error: {getattr(e, 'msg', str(e))}")
        return {
            'success': False,
            'error': str(e),
            'error_details': {
                'errno': getattr(e, 'errno', None),
                'sqlstate': getattr(e, 'sqlstate', None),
                'msg': getattr(e, 'msg', str(e))
            }
        }
    except Exception as e:
        if conn:
            try: conn.rollback()
            except Exception: pass
        status.error(f"Error: {str(e)}")
        return {'success': False, 'error': str(e)}
    finally:
        try:
            if cursor: cursor.close()
        except Exception: pass
        try:
            if conn: conn.close()
        except Exception: pass

def progress_value_bump(step=5):
    """Track progress position in session since Streamlit bar doesn't expose current value."""
    if 'proc_progress_value' not in st.session_state:
        st.session_state['proc_progress_value'] = 20
    st.session_state['proc_progress_value'] = min(100, st.session_state['proc_progress_value'] + step)
    return st.session_state['proc_progress_value']

# ---------- NEW: common renderer for execution result ----------
def render_exec_result(proc_name: str, result: dict):
    if result.get('success'):
        st.success(f"‚úÖ {result['message']}")
        if proc_name == "update_Broadband_daily":
            st.markdown(
                """
                <div style="
                    background-color:#fff8e1;
                    border-left:5px solid #ff9800;
                    padding:10px 15px;
                    border-radius:6px;
                    margin-top:10px;
                    ">
                    üîÑ <b>Procedure <code>update_Broadband_daily</code> executed successfully.</b><br>
                    ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤ <a href="https://lookerstudio.google.com/reporting/1483b6e3-3477-4906-8966-ec276423ec27"
                    target="_blank" style="color:#d32f2f; font-weight:bold; text-decoration:underline;">
                    ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠ Refresh Dashboard</a> ‡πÉ‡∏ô Looker Studio
                </div>
                """,
                unsafe_allow_html=True
            )
        if result.get('results'):
            for idx, res in enumerate(result['results']):
                st.write(f"**Result Set {idx + 1}:**")
                df_result = pd.DataFrame(res)
                st.dataframe(df_result, use_container_width=True)
                csv_data = df_result.to_csv(index=False)
                st.download_button(
                    "üì• Download CSV",
                    csv_data,
                    f"{proc_name}_result_{idx+1}.csv",
                    "text/csv",
                    key=f"download_csv_{proc_name}_{idx}"
                )
        if result.get('rows_affected'):
            st.info(f"Rows affected: {result.get('rows_affected')}")
        if result.get('warnings'):
            with st.expander("‚ö†Ô∏è Warnings"):
                for warning in result['warnings']:
                    st.warning(f"{warning[0]}: {warning[2]}")
        st.session_state.execution_history.append({'procedure': proc_name,'status': 'success','timestamp': datetime.now()})
    else:
        st.error("‚ùå Execution failed")
        if result.get('error_details'):
            details = result['error_details']
            st.error(f"**Error:** {details.get('msg')}")
            if details.get('errno'):
                st.caption(f"Error Code: {details['errno']}")
            if details.get('sqlstate'):
                st.caption(f"SQL State: {details['sqlstate']}")
        else:
            st.error(result.get('error', 'Unknown error'))
        st.session_state.execution_history.append({'procedure': proc_name,'status': 'failed','timestamp': datetime.now()})

# ---------- NEW: favorites helpers ----------
def add_favorite(name: str):
    favs = set(st.session_state.get('favorites', []))
    favs.add(name)
    st.session_state['favorites'] = list(favs)

def remove_favorite(name: str):
    favs = set(st.session_state.get('favorites', []))
    favs.discard(name)
    st.session_state['favorites'] = list(favs)

def render_favorites_block():
    st.subheader("‚≠ê Favorites")
    favs = st.session_state.get('favorites', [])
    if not favs:
        st.caption("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏õ‡∏£‡∏î")
        return
    for name in favs:
        c1, c2, c3 = st.columns([2,1,1])
        with c1:
            st.write(name)
        with c2:
            if st.button("‚ñ∂Ô∏è Run", key=f"fav_run_{name}"):
                st.session_state['PROC_RUN_EVENT'] = {'name': name, 'params': None}
        with c3:
            if st.button("üóëÔ∏è Remove", key=f"fav_del_{name}"):
                remove_favorite(name)
                st.rerun()

# ===== CSS STYLING =====
st.markdown("""
<style>
    .main-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1rem; border-radius: 8px; margin-bottom: 1rem; text-align: center; color: white; }
    .metric-card { background: #f0f2f6; padding: 1rem; border-radius: 8px; text-align: center; margin: 0.5rem 0; border: 1px solid #e0e0e0; }
    .status-success { background: #d4edda; padding: 0.5rem; border-radius: 4px; color: #155724; margin: 0.5rem 0; }
    .status-error { background: #f8d7da; padding: 0.5rem; border-radius: 4px; color: #721c24; margin: 0.5rem 0; }
    .file-info { background: white; padding: 1rem; border-radius: 8px; border-left: 4px solid #9CAF88; box-shadow: 0 2px 8px rgba(139, 69, 19, 0.1); margin: 1rem 0; }
    .header-match { background: #d4edda; color: #155724; padding: 0.25rem 0.5rem; border-radius: 4px; margin: 0.1rem; display: inline-block; font-size: 0.85rem; font-weight: bold; }
    .header-no-match { background: #f8d7da; color: #721c24; padding: 0.25rem 0.5rem; border-radius: 4px; margin: 0.1rem; display: inline-block; font-size: 0.85rem; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# ===== Utility: Safe CSV reader (‡πÉ‡∏´‡∏°‡πà) =====
def read_csv_safely(file_or_bytes, *, sep=None):
    """‡∏≠‡πà‡∏≤‡∏ô CSV ‡πÇ‡∏î‡∏¢‡∏•‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢ encoding ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞‡∏Å‡∏±‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î/‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏•‡πâ‡∏°"""
    if hasattr(file_or_bytes, "getvalue"):
        raw = file_or_bytes.getvalue()
    elif hasattr(file_or_bytes, "read"):
        raw = file_or_bytes.read()
    else:
        raw = file_or_bytes  # assume bytes

    encodings_try = ['utf-8-sig', 'cp874', 'tis-620', 'iso-8859-11', 'utf-16', 'utf-16le', 'utf-16be', 'latin1']
    last_err = None
    for enc in encodings_try:
        try:
            buf = BytesIO(raw)
            df = pd.read_csv(
                buf,
                encoding=enc,
                encoding_errors='replace',
                engine='python',
                sep=sep,                 # sniff ‡∏ñ‡πâ‡∏≤ None
                on_bad_lines='skip',     # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏û‡∏¥‡∏Å‡∏•
                dtype=str                # ‡∏Å‡∏±‡∏ô type ‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô
            )
            df.attrs['__encoding__'] = enc
            return df
        except Exception as e:
            last_err = e
            continue
    raise last_err or Exception("Cannot decode CSV with known Thai encodings")

# ===== FILE MERGER CLASS =====
class FileMerger:
    def __init__(self):
        self.uploaded_files = []
        self.processed_data = {}
        self.merged_df = None
        self.header_mapping = {}


    def process_uploaded_files(self, files):
        processed = {}
        for file in files:
            file_info = {'name': file.name, 'size': file.size, 'type': self.get_file_type(file.name)}
            try:
                if file_info['type'] == 'csv':
                    # ‚úÖ ‡∏≠‡πà‡∏≤‡∏ô CSV ‡πÅ‡∏ö‡∏ö‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô string
                    df = pd.read_csv(file, dtype=str, encoding='utf-8', keep_default_na=False)
                    file_info['succeeded_encoding'] = getattr(df.attrs, '__encoding__', 'utf-8')
                    file_info['sheets'] = ['Sheet1']
                    file_info['data'] = {'Sheet1': df}
    
                elif file_info['type'] == 'excel':
                    # ‚úÖ ‡∏≠‡πà‡∏≤‡∏ô Excel ‡∏ó‡∏∏‡∏Å‡∏ä‡∏µ‡∏ï‡πÅ‡∏ö‡∏ö string ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô
                    excel_file = pd.ExcelFile(file)
                    file_info['sheets'] = excel_file.sheet_names
                    file_info['data'] = {
                        sheet: pd.read_excel(excel_file, sheet_name=sheet, dtype=str, keep_default_na=False)
                        for sheet in excel_file.sheet_names
                    }
    
                processed[file.name] = file_info
    
            except Exception as e:
                st.error(f"Error processing {file.name}: {str(e)}")
        return processed


    def get_file_type(self, filename):
        if filename.lower().endswith('.csv'): return 'csv'
        elif filename.lower().endswith(('.xlsx', '.xls')): return 'excel'
        return 'unknown'

    def analyze_headers(self, processed_data, selected_sheets, selected_files):
        all_headers = set(); file_headers = {}; has_mismatch = False
        for filename, file_info in processed_data.items():
            if selected_files.get(filename, True):
                sheet_name = selected_sheets.get(filename, file_info['sheets'][0])
                if sheet_name in file_info['data']:
                    df = file_info['data'][sheet_name]
                    headers = list(df.columns)
                    file_headers[filename] = headers
                    all_headers.update(headers)
        if len(file_headers) > 1:
            reference_headers = set(next(iter(file_headers.values())))
            for _, headers in file_headers.items():
                if set(headers) != reference_headers:
                    has_mismatch = True; break
        return list(all_headers), has_mismatch, file_headers

    def merge_files(self, processed_data, selected_sheets, selected_files, header_mapping=None, excluded_headers=None):
        merged_dfs = []
        for filename, file_info in processed_data.items():
            if selected_files.get(filename, True):
                sheet_name = selected_sheets.get(filename, file_info['sheets'][0])
                if sheet_name in file_info['data']:
                    df = file_info['data'][sheet_name].copy()
                    if excluded_headers and filename in excluded_headers:
                        columns_to_keep = [c for c in df.columns if c not in excluded_headers[filename]]
                        df = df[columns_to_keep]
                    if header_mapping and filename in header_mapping:
                        df.rename(columns=header_mapping[filename], inplace=True)
                    df['_source_file'] = filename
                    merged_dfs.append(df)


        if merged_dfs:
            merged_df = pd.concat(merged_dfs, ignore_index=True, sort=False)
        
            # ‚úÖ ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ó‡∏∏‡∏Å column ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô string ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏à‡∏∏‡∏î‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏° / ‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏´‡∏≤‡∏¢
            merged_df = merged_df.applymap(lambda x: str(x).strip() if pd.notna(x) else "")
        
            return merged_df
        
        return pd.DataFrame()

st.markdown("""
<style>
/* ===== Force full width for inputs and buttons ===== */

/* ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö text_input / password_input / selectbox */
div.stTextInput, div.stPasswordInput, div.stSelectbox, div.stFileUploader {
    width: 100% !important;
}

/* ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏∏‡πà‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î */
div.stButton > button {
    width: 100% !important;
    display: block;
    text-align: center;
}

/* ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á columns ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡πÄ‡∏ô‡∏≠‡∏£‡πå import section */
section.main div.block-container {
    max-width: 100% !important;
    padding-right: 2rem;
    padding-left: 2rem;
}
</style>
""", unsafe_allow_html=True)


# ===== TAB 1: IMPORT DATA =====
def render_import_tab():
    st.subheader("üìä Quick Stats")
    col_stat1, col_stat2, col_stat3 = st.columns(3)
    with col_stat1:
        try:
            tables_info = get_cached_tables_info()
            tables = [table['TABLE_NAME'] for table in tables_info] if tables_info else []
            # üõ°Ô∏è ‡∏ã‡πà‡∏≠‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ user ‡πÄ‡∏´‡πá‡∏ô
            HIDDEN_TABLES = ["user_permissions","sn"]
            tables = [t for t in tables if t not in HIDDEN_TABLES]
            st.metric("üìÅ Total Tables", len(tables))
        except:
            st.metric("üìÅ Total Tables", "N/A")
    with col_stat2:
        if 'connection_status' in st.session_state and st.session_state.connection_status:
            st.metric("üîå Database Status", "Connected", delta="Online", delta_color="normal")
        else:
            st.metric("üîå Database Status", "Disconnected", delta="Offline", delta_color="inverse")
    with col_stat3:
        if st.button("üîÑ Refresh All", use_container_width=True, key="refresh_import_top"):
            st.cache_data.clear()
            st.rerun()

    st.divider()
    st.header("üìÅ File Import to Database")

    # === Database & Processor setup ===
    if 'db_manager' not in st.session_state:
        st.session_state.db_manager = DatabaseManager()
    if 'file_processor' not in st.session_state:
        st.session_state.file_processor = FileProcessor()

    try:
        tables_info = get_cached_tables_info()
        tables = [table['TABLE_NAME'] for table in tables_info] if tables_info else []
        # üõ°Ô∏è ‡∏ã‡πà‡∏≠‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ user ‡πÄ‡∏´‡πá‡∏ô
        HIDDEN_TABLES = ["user_permissions", "mysql", "performance_schema", "sys"]
        tables = [t for t in tables if t not in HIDDEN_TABLES]
    except Exception as e:
        st.warning(f"Could not get table info: {e}")
        tables = []
        tables_info = []

    selected_table = st.selectbox("üéØ Select Target Table", options=[""] + tables, help="Choose the table where you want to import your data")

    if selected_table:
        # ===== Show Table Info =====
        if tables_info:
            table_details = next((t for t in tables_info if t.get('TABLE_NAME') == selected_table), None)
            if table_details:
                col1_info, col2_info, col3_info = st.columns(3)
                with col1_info:
                    row_count = table_details.get('TABLE_ROWS', 0) or 0
                    st.metric("üìä Rows", f"{row_count:,}")
                with col2_info:
                    update_time = table_details.get('UPDATE_TIME')
                    if update_time:
                        try:
                            if isinstance(update_time, str):
                                last_update = update_time[:10]
                            else:
                                last_update = update_time.strftime("%Y-%m-%d")
                            st.metric("üïí Updated", last_update)
                        except:
                            st.metric("üïí Updated", "Unknown")
                with col3_info:
                    data_length = table_details.get('DATA_LENGTH', 0) or 0
                    if data_length > 0:
                        size_mb = data_length / (1024 * 1024)
                        st.metric("üíæ Size", f"{size_mb:.0f} MB")

        # ===== Show Preview Button =====
        st.subheader(f"üëÄ Preview: {selected_table}")
        if st.button("üîÑ Show Preview", type="secondary"):
            try:
                with st.spinner("Loading preview..."):
                    preview_data = get_cached_table_preview(selected_table, 5)
                if not preview_data.empty:
                    st.dataframe(preview_data, use_container_width=True, hide_index=True)
                    st.success(f"üìä Showing last 5 rows from {len(preview_data.columns)} columns")
                else:
                    st.warning("üì≠ Table is empty or preview unavailable")
            except Exception as e:
                st.error(f"‚ùå Error: {str(e)}")

        # ===== Upload File =====
        st.subheader("üì§ Upload File")
        uploaded_file = st.file_uploader("Choose a file to import", type=['csv', 'xlsx', 'xls'], help="Max size: 200MB", key="import_uploader")

        if uploaded_file:
            st.markdown(f"""
            <div class="file-info">
                <h4>üìÑ {uploaded_file.name}</h4>
                <p><strong>Size:</strong> {uploaded_file.size / 1024:.2f} KB</p>
                <p><strong>Type:</strong> {uploaded_file.type}</p>
            </div>
            """, unsafe_allow_html=True)

            try:
                with st.spinner("Reading file..."):
                    if uploaded_file.name.endswith('.csv'):
                        df = read_csv_safely(uploaded_file)
                    else:
                        df = pd.read_excel(uploaded_file)

                st.success(f"‚úÖ File loaded: {len(df)} rows, {len(df.columns)} columns")
                st.caption(f"Encoding: {getattr(df.attrs, '__encoding__', 'auto') if uploaded_file.name.endswith('.csv') else 'n/a'}")

                st.subheader("üìã Data Preview")
                st.dataframe(df.head(10), use_container_width=True)

                # ===== Column Mapping =====
                st.subheader("üîó Column Mapping")
                table_columns = get_cached_table_columns(selected_table)
                if not table_columns:
                    st.error("Cannot get table columns")
                    return

                db_column_names = [col['COLUMN_NAME'] for col in table_columns]
                file_columns = list(df.columns)

                st.info(f"**File Columns:** {len(file_columns)} | **Table Columns:** {len(db_column_names)}")
                column_mapping = {}
                cols = st.columns(2)
                with cols[0]:
                    st.write("**File Column**")
                with cols[1]:
                    st.write("**‚Üí Database Column**")
                  
                for file_col in file_columns:
                    c1, c2 = st.columns(2)
                    with c1:
                        st.text(file_col)
                    with c2:
                        default_index = 0
                        if file_col in db_column_names:
                            default_index = db_column_names.index(file_col)
                        selected_db_col = st.selectbox(
                            f"Map {file_col}",
                            options=["-- Skip --"] + db_column_names,
                            index=default_index + 1 if file_col in db_column_names else 0,
                            key=f"mapping_{file_col}",
                            label_visibility="collapsed"
                        )
                        if selected_db_col != "-- Skip --":
                            column_mapping[file_col] = selected_db_col

                if column_mapping:
                    st.success(f"‚úÖ Mapped {len(column_mapping)} columns")
                    with st.expander("View Mapping Details"):
                        for file_col, db_col in column_mapping.items():
                            st.write(f"**{file_col}** ‚Üí **{db_col}**")
                else:
                    st.warning("‚ö†Ô∏è No columns mapped")

                # ===== AUTH + IMPORT =====
                st.divider()
                
                # --- ‡∏ä‡πà‡∏≠‡∏á‡∏Å‡∏£‡∏≠‡∏Å Secret Key ‡πÄ‡∏ï‡πá‡∏°‡πÅ‡∏ô‡∏ß‡∏Å‡∏ß‡πâ‡∏≤‡∏á ---
                secret_key = st.text_input(
                    "Secret Key to unlock import",
                    type="password",
                    placeholder="Enter your secret key",
                    key="import_secret_key"
                )
                
                user_perm = get_user_permission(secret_key)
  
                if not user_perm:
                    st.warning("üîë Enter correct key to unlock Import Data button.", icon="üîí")
                    import_disabled = True
                else:
                    role = user_perm["role"]
                    allowed_tables = user_perm.get("allowed_tables", [])
                    if role == "Admin" or selected_table in allowed_tables:
                        st.success(f"‚úÖ Authorized as **{role}**")
                        import_disabled = False
                    else:
                        st.error(f"üö´ You are not allowed to import into `{selected_table}`.")
                        import_disabled = True


                    # --- ‡∏õ‡∏∏‡πà‡∏° Import Data ---
                    if st.button("üöÄ Import Data", type="primary", use_container_width=True, disabled=import_disabled):
                        if not column_mapping:
                            st.error("Please map at least one column")
                        else:
                            # üîπ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Log
                            try:
                                username = secret_key.strip()
                                db = st.session_state.get('db_manager') or DatabaseManager()
                                conn = db.get_connection()
                                cursor = conn.cursor()
                                cursor.execute("""
                                    INSERT INTO activity_log (username, action, target, ip_address, details)
                                    VALUES (%s, %s, %s, %s, %s)
                                """, (
                                    username,
                                    "Import Data",
                                    selected_table,
                                    st.session_state.get('client_ip', 'unknown'),
                                    f"rows={len(df)}"
                                ))
                                conn.commit()
                                cursor.close()
                                conn.close()
                            except Exception as log_err:
                                st.warning(f"‚ö†Ô∏è Failed to write activity log: {log_err}")
                    
                            # üîπ Import Data ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                            fresh_db = DatabaseManager()
                            with st.spinner(f"Importing {len(df)} rows..."):
                                result = fresh_db.import_data(selected_table, df, column_mapping)
                            fresh_db.close_connection()
                    
                            # üîπ ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå Import
                            if result.get('success'):
                                st.success(f"‚úÖ {result['message']}")
                                st.balloons()
                                st.cache_data.clear()
                                st.metric("Rows Imported", result.get('rows_affected', 0))
                    
                                # ===========================================================
                                # üîÆ ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ Procedure ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (AI Recommendation Unified)
                                # ===========================================================
                                try:
                                    current_action = f"Import Data:{selected_table}"
                                    suggestion, freq, confidence = recommend_action(current_action) or (None, 0, 0)
                    
                                    # ===================== AI Recommendation (Professional Version) =====================
                                    st.divider()
                                    st.subheader("üí° AI Recommendation")
                    
                                    if suggestion:
                                        proc_name = suggestion.replace("Execute Procedure:", "").strip()
                    
                                        # ‚úÖ ‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô
                                        if confidence >= 80:
                                            conf_color = "#2ecc71"  # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß
                                            emoji = "üü¢"
                                            conf_text = "‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å"
                                        elif confidence >= 50:
                                            conf_color = "#f1c40f"  # ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á
                                            emoji = "üü°"
                                            conf_text = "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á"
                                        else:
                                            conf_color = "#e74c3c"  # ‡πÅ‡∏î‡∏á
                                            emoji = "üî¥"
                                            conf_text = "‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πà‡∏≥"
                    
                                        # ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÅ‡∏ö‡∏ö‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
                                        st.markdown(f"""
                                        <div style="background-color:#f8f9fb;border-left:6px solid {conf_color};
                                                    padding:12px 18px;border-radius:10px;font-size:15px;line-height:1.6;">
                                            <strong>ü§ñ Smart AI Operator:</strong><br>
                                            ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ß‡πà‡∏≤<br>
                                            <span style="color:#2d3436;"><b>Procedure <code>{proc_name}</code></b></span> 
                                            ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ<br>
                                            <span style="font-size:13.5px;color:#636e72;">
                                            ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏î‡∏¥‡∏° <b>{freq}</b> ‡∏Ñ‡∏£‡∏±‡πâ‡∏á 
                                            ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô <b style="color:{conf_color};">{emoji} {confidence:.1f}% ({conf_text})</b>
                                            </span>
                                        </div>
                                        """, unsafe_allow_html=True)

                                        # ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô pattern ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö AI ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö)
                                        if confidence > 0:
                                            total_patterns = round(freq / (confidence / 100))
                                        else:
                                            total_patterns = freq
                                        
                                        # ‚úÖ ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏ö‡∏ö professional
                                        freq_fmt = f"{freq:,}"
                                        total_fmt = f"{total_patterns:,}"
                                        conf_fmt = f"{confidence:,.2f}"
                                        
                                        # ‚úÖ Confidence Bar + Explanation
                                        st.markdown(f"""
                                        <div style="background-color:#eaecef;border-radius:8px;margin-top:6px;">
                                          <div style="width:{confidence}%;background-color:{conf_color};
                                                      height:12px;border-radius:8px;"></div>
                                        </div>
                                        
                                        <div style="font-size:13px;color:#555;margin-top:6px;">
                                          <b style="color:{conf_color};">Confidence Level:</b>
                                          <span style="font-weight:bold;color:{conf_color};">{conf_fmt}%</span>
                                        </div>
                                        
                                        <div style="font-size:12.5px; color:#7f8c8d; margin-top:2px; font-family:Consolas, 'Courier New', monospace;">
                                          {freq_fmt} √∑ {total_fmt} √ó 100  =  <b>{conf_fmt}%</b>
                                        </div>
                                        """, unsafe_allow_html=True)


                                        # ‚úÖ ‡∏õ‡∏∏‡πà‡∏°‡∏£‡∏±‡∏ô Procedure ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ (‡πÉ‡∏ä‡πâ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ó‡∏µ‡πà authorize ‡πÅ‡∏•‡πâ‡∏ß)
                                        if not import_disabled:
                                            button_key = f"run_ai_recommendation_{selected_table}_{proc_name}"
                                            st.markdown("<br>", unsafe_allow_html=True)
                                        
                                            # --- ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ event pending ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ---
                                            if st.button(
                                                f"‚ñ∂Ô∏è ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô Procedure `{proc_name}`",
                                                type="primary",
                                                use_container_width=True,
                                                key=button_key
                                            ):
                                                # üß† ‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô rerun
                                                st.session_state["AI_RUN_TRIGGERED"] = True
                                                st.session_state["AI_PROC_NAME"] = proc_name
                                                st.session_state["AI_CONFIDENCE"] = confidence
                                                st.rerun()
                                        
                                            # --- ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ flag ‡∏ß‡πà‡∏≤‡∏õ‡∏∏‡πà‡∏°‡∏ñ‡∏π‡∏Å‡∏Å‡∏î‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ---
                                            if st.session_state.get("AI_RUN_TRIGGERED", False):
                                                proc_to_run = st.session_state.get("AI_PROC_NAME", "")
                                                conf_level = st.session_state.get("AI_CONFIDENCE", 0.0)
                                        
                                                st.info(f"‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô Procedure `{proc_to_run}` ...")
                                        
                                                try:
                                                    result = execute_procedure_with_progress(proc_to_run)
                                                    render_exec_result(proc_to_run, result)
                                                    log_activity(
                                                        username=username,
                                                        action="Run Procedure (AI Recommendation)",
                                                        target=proc_to_run,
                                                        details=f"Executed by Smart AI Operator (confidence={conf_level:.1f}%)"
                                                    )
                                                    st.toast(f"‚úÖ Procedure `{proc_to_run}` executed successfully.", icon="‚úÖ")
                                                except Exception as e:
                                                    st.exception(e)
                                                    st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô `{proc_to_run}`: {e}")
                                                finally:
                                                    # üßπ ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï flag ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡∏ã‡πâ‡∏≥
                                                    st.session_state["AI_RUN_TRIGGERED"] = False
                                        
                                        else:
                                            st.info("üîí ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô Procedure ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥") 
 
                                    else:
                                        # ‚úÖ ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠
                                        st.markdown(f"""
                                        <div style="background-color:#f8f9fb;border-left:6px solid #b2bec3;
                                                    padding:12px 18px;border-radius:10px;font-size:15px;line-height:1.6;">
                                            <strong>ü§ñ Smart AI Operator:</strong><br>
                                            ‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ<br>
                                            ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ pattern ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
                                        </div>
                                        """, unsafe_allow_html=True)
                    
                                        # Progress Bar 0%
                                        st.markdown("""
                                        <div style="background-color:#eaecef;border-radius:8px;margin-top:6px;">
                                          <div style="width:0%;background-color:#b2bec3;
                                                      height:12px;border-radius:8px;"></div>
                                        </div>
                                        <div style="font-size:13px;color:#555;margin-top:2px;">
                                          Confidence Level: <b style="color:#b2bec3;">0.0%</b>
                                        </div>
                                        """, unsafe_allow_html=True)
                    
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Suggestion module error: {e}")
                    
                            else:
                                st.error(f"‚ùå Import failed: {result.get('error')}")
 

                with c2:
                    if st.button("üîÑ Reset", type="secondary"):
                        st.rerun()

            except Exception as e:
                st.error(f"‚ùå Error processing file: {str(e)}")
                st.exception(e)


def log_activity(username, action, target, details=None):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Log ‡∏•‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    try:
        db = st.session_state.get('db_manager') or DatabaseManager()
        conn = db.get_connection()
        cursor = conn.cursor()
        ip = st.session_state.get('client_ip', 'unknown')
        sql = """
            INSERT INTO activity_log (username, action, target, ip_address, details)
            VALUES (%s, %s, %s, %s, %s)
        """
        cursor.execute(sql, (username, action, target, ip, str(details)))
        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Failed to write activity log: {e}")

# ====== üîÆ AI Suggestion Section (Auto Procedure Recommendation) ======

def recommend_action(current_action):
    """‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ Procedure ‡∏ó‡∏µ‡πà‡∏°‡∏±‡∏Å‡∏ñ‡∏π‡∏Å‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏á Import ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡πà‡∏≤ Confidence (%)"""
    try:
        db = st.session_state.get('db_manager') or DatabaseManager()
        conn = db.get_connection()
        cursor = conn.cursor()

        # ‡∏î‡∏∂‡∏á pattern ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏´‡∏•‡∏±‡∏á import (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤ 10 ‡∏ô‡∏≤‡∏ó‡∏µ)
        query = """
            SELECT next_action, COUNT(*) AS freq
            FROM (
                SELECT 
                    CONCAT(a.action, ':', a.target) AS prev_action,
                    CONCAT(b.action, ':', b.target) AS next_action
                FROM activity_log a
                JOIN activity_log b 
                  ON a.username = b.username
                 AND b.timestamp > a.timestamp
                 AND TIMESTAMPDIFF(MINUTE, a.timestamp, b.timestamp) <= 30
                WHERE a.action = 'Import Data'
            ) seq
            WHERE prev_action = %s
              AND (
                    next_action LIKE 'Run Procedure%%'
                 OR next_action LIKE 'Execute Procedure%%'
              )
            GROUP BY next_action
            ORDER BY freq DESC
            LIMIT 1;
        """
        cursor.execute(query, (current_action,))
        row = cursor.fetchone()

        # ‡∏î‡∏∂‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Import ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì %
        total_query = "SELECT COUNT(*) FROM activity_log WHERE CONCAT(action, ':', target) = %s"
        cursor.execute(total_query, (current_action,))
        total_imports = cursor.fetchone()[0] or 0

        cursor.close()
        conn.close()

        if row:
            next_action, freq = row
            confidence = (freq / total_imports * 100) if total_imports > 0 else 0
            return next_action, freq, confidence
    except Exception as e:
        st.warning(f"‚ö†Ô∏è AI suggestion failed: {e}")
    return None, None, 0





# ===== TAB 2: RUN PROCEDURES (with event flags) =====
def render_procedures_tab():
    st.header("‚öôÔ∏è Database Procedures & Updates")

    # ====== Enable / Disable Tab ======
    enabled = st.toggle("Enable this tab (load from DB)", value=False,
                        help="Turn on only when you want to work with procedures")
    if not enabled:
        st.info("This tab is idle. Turn on the toggle to load procedures.")
        return

    if 'db_manager' not in st.session_state:
        st.session_state.db_manager = DatabaseManager()

    # ====== SEARCH / LOAD ======
    st.subheader("üîé Search / Load Procedures")
    col_a, col_b, col_c, col_d, col_e = st.columns([2, 1, 1, 1, 1])
    with col_a:
        name_filter = st.text_input(
            "Procedure name",
            value=st.session_state.get('last_proc_filter', ""),
            placeholder="‡πÄ‡∏ä‡πà‡∏ô %R06% ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡πá‡∏°"
        )
    with col_b:
        limit = st.number_input("Limit", min_value=1, max_value=500, value=50, step=10)
    with col_c:
        exact_only = st.checkbox("Exact name",
                                 value=st.session_state.get('last_proc_exact', False))
    with col_d:
        do_load = st.button("üì• Load", type="primary", use_container_width=True)
    with col_e:
        do_clear_loaded = st.button("üßπ Clear", use_container_width=True)

    if do_clear_loaded:
        st.session_state.loaded_procedures = []
        st.session_state['last_proc_filter'] = ""
        st.session_state['last_proc_exact'] = False
        st.toast("Cleared loaded procedures")

    if do_load:
        pattern = name_filter or "%"
        if exact_only and name_filter:
            pattern = name_filter
        procs = get_stored_procedures(pattern, limit)
        st.session_state.loaded_procedures = procs
        st.session_state['last_proc_filter'] = name_filter
        st.session_state['last_proc_exact'] = exact_only
        if procs:
            st.success(f"Loaded {len(procs)} procedure(s)")
        else:
            st.warning("No procedures matched your filter.")

    procedures = st.session_state.get("loaded_procedures", [])
    st.divider()

    # ====== SHOW PROCEDURES ======
    st.subheader("üîß Stored Procedures")
    if not procedures:
        st.warning("‚ö†Ô∏è No procedures loaded. ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î Load ‡∏Å‡πà‡∏≠‡∏ô")
        return

    search_query = st.text_input(
        "Filter in results (client-side)",
        placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤",
        key="search_proc_client"
    )
    filtered = [p for p in procedures if
                search_query.lower() in p["ROUTINE_NAME"].lower()] if search_query else procedures

    for proc in filtered:
        with st.expander(f"üì¶ {proc['ROUTINE_NAME']} ({proc['ROUTINE_TYPE']})"):
            left, right = st.columns([1, 1])
            with left:
                st.write(f"**Type:** {proc['ROUTINE_TYPE']}")
                if proc.get('ROUTINE_COMMENT'):
                    st.write(f"**Description:** {proc['ROUTINE_COMMENT']}")
                if proc.get('CREATED'):
                    st.write(f"**Created:** {proc['CREATED']}")
                if proc.get('LAST_ALTERED'):
                    st.write(f"**Last Altered:** {proc['LAST_ALTERED']}")
            with right:
                st.info("No parameters required")

            st.divider()

            # ‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©
            if proc["ROUTINE_NAME"] == "update_Broadband_daily":
                st.markdown(
                    "<span style='color:red;font-weight:bold;'>‚ö†Ô∏è ‡∏Å‡πà‡∏≠‡∏ô Run ‡πÉ‡∏´‡πâ Import ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Ticket ‡∏ó‡∏±‡πâ‡∏á TTS ‡πÅ‡∏•‡∏∞ SCOMS ‡∏•‡∏á Broadband_daily ‡∏Å‡πà‡∏≠‡∏ô</span>",
                    unsafe_allow_html=True
                )

            # ===== AUTH SECTION =====
            st.markdown("#### üîë Authorization")
            key_col, status_col = st.columns([2, 1])
            with key_col:
                local_key = st.text_input(
                    f"Enter Secret Key (for execute permission)",
                    type="password",
                    placeholder="Enter key...",
                    key=f"key_{proc['ROUTINE_NAME']}"
                ).strip()
            with status_col:
                user_perm = get_user_permission(local_key) if local_key else None
                if not user_perm:
                    st.info("üëÅ Guest mode ‚Äî execute locked")
                    execute_disabled = True
                    role = "Guest"
                else:
                    role = user_perm["role"]
                    allowed_procs = user_perm.get("allowed_procedures", [])
                    if role == "Admin" or proc["ROUTINE_NAME"] in allowed_procs:
                        st.success(f"‚úÖ Authorized as **{role}**")
                        execute_disabled = False
                    else:
                        st.error(f"üö´ Not allowed to execute `{proc['ROUTINE_NAME']}`")
                        execute_disabled = True

            # ===== EXECUTE BUTTON =====
            exec_col, note_col = st.columns([1, 3])
            with exec_col:
                if st.button(
                    "‚ñ∂Ô∏è Execute",
                    key=f"exec_{proc['ROUTINE_NAME']}",
                    type="primary",
                    use_container_width=True,
                    disabled=execute_disabled,
                ):
                    try:
                        db = st.session_state.get("db_manager") or DatabaseManager()
                        conn = db.get_connection()
                        cursor = conn.cursor()
                        cursor.execute(
                            """
                            INSERT INTO activity_log (username, action, target, ip_address, details)
                            VALUES (%s, %s, %s, %s, %s)
                            """,
                            (
                                local_key,
                                "Execute Procedure",
                                proc["ROUTINE_NAME"],
                                st.session_state.get("client_ip", "unknown"),
                                "{}",
                            ),
                        )
                        conn.commit()
                        cursor.close()
                        conn.close()
                    except Exception as log_err:
                        st.warning(f"‚ö†Ô∏è Failed to write log: {log_err}")

                    st.session_state["PROC_RUN_EVENT"] = {
                        "name": proc["ROUTINE_NAME"],
                        "params": None,
                    }
            with note_col:
                st.caption("Only authorized users can execute this procedure.")

    # ===== EVENT HANDLING =====
    event_run = st.session_state.get('PROC_RUN_EVENT')
    if event_run:
        st.session_state['proc_progress_value'] = 20
        result = execute_procedure_with_progress(event_run['name'], event_run.get('params'))
        render_exec_result(event_run['name'], result)
        st.session_state['PROC_RUN_EVENT'] = None

 

    # ===== RIGHT: STATS =====
    st.divider()
    st.subheader("üìä Quick Stats")
    
    if procedures:
        st.metric("Total Procedures (loaded)", len(procedures))
    
    if st.session_state.execution_history:
        success_count = sum(1 for h in st.session_state.execution_history if h['status'] == 'success')
        failed_count = len(st.session_state.execution_history) - success_count
        st.metric("Executions", len(st.session_state.execution_history))
    
        cols = st.columns(2)
        with cols[0]:
            st.metric("‚úÖ Success", success_count)
        with cols[1]:
            st.metric("‚ùå Failed", failed_count)
    
    st.divider()
    
    if st.button("üßπ Clear History", use_container_width=True):
        st.session_state.execution_history = []
        st.rerun()
    
    if st.button("üóÇÔ∏è Clear Cache (procedures)", use_container_width=True):
        get_stored_procedures.clear()
        st.session_state.loaded_procedures = []
        st.toast("Cleared cached procedures & session list")

# ===== TAB 3: FILE MERGER =====
def render_merger_tab():
    st.header("üìÅ File Merger")
    st.write("‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå CSV ‡πÅ‡∏•‡∏∞ Excel ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô")
    if 'merger' not in st.session_state:
        st.session_state.merger = FileMerger()
    if 'merger_processed_data' not in st.session_state:
        st.session_state.merger_processed_data = {}
    if 'merger_merged_df' not in st.session_state:
        st.session_state.merger_merged_df = None
    if 'merger_selected_files' not in st.session_state:
        st.session_state.merger_selected_files = {}
    merger = st.session_state.merger

    st.subheader("üì§ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå")
    uploaded_files = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡∏´‡∏£‡∏∑‡∏≠ Excel", type=['csv', 'xlsx', 'xls'], accept_multiple_files=True, help="‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå CSV ‡πÅ‡∏•‡∏∞ Excel ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå", key="merger_uploader")

    if uploaded_files:
        if len(uploaded_files) != len(st.session_state.get('merger_last_uploaded', [])):
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå..."):
                st.session_state.merger_processed_data = merger.process_uploaded_files(uploaded_files)
                st.session_state.merger_last_uploaded = uploaded_files
                st.session_state.merger_merged_df = None
                st.session_state.merger_selected_files = {f.name: True for f in uploaded_files}

    if st.session_state.merger_processed_data:
        if len(st.session_state.merger_processed_data) > 1:
            st.subheader("üéØ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°")
            cols = st.columns(min(len(st.session_state.merger_processed_data), 3))
            for i, (filename, file_info) in enumerate(st.session_state.merger_processed_data.items()):
                with cols[i % 3]:
                    selected = st.checkbox(filename, value=st.session_state.merger_selected_files.get(filename, True), key=f"merger_select_{filename}", help=f"‡∏Ç‡∏ô‡∏≤‡∏î: {file_info['size']/1024:.1f} KB")
                    st.session_state.merger_selected_files[filename] = selected
            selected_count = sum(st.session_state.merger_selected_files.values())
            if selected_count == 0:
                st.error("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡πÑ‡∏ü‡∏•‡πå"); return
        else:
            filename = list(st.session_state.merger_processed_data.keys())[0]
            st.session_state.merger_selected_files = {filename: True}

        st.subheader("üìã ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
        cols = st.columns([2, 1])
        with cols[0]:
            selected_sheets = {}
            for filename, file_info in st.session_state.merger_processed_data.items():
                is_selected = st.session_state.merger_selected_files.get(filename, True)
                with st.expander(f"{'‚úÖ' if is_selected else '‚ùå'} {filename}", expanded=is_selected):
                    col_info, col_sheet = st.columns([2, 1])
                    with col_info:
                        st.markdown(f"**‡∏Ç‡∏ô‡∏≤‡∏î:** {file_info['size']/1024:.2f} KB  \n**‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:** {file_info['type'].upper()}  \n**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Sheets:** {len(file_info['sheets'])}")
                        if 'succeeded_encoding' in file_info:
                            st.caption(f"Encoding: {file_info.get('succeeded_encoding','auto')}")
                    with col_sheet:
                        if len(file_info['sheets']) > 1:
                            selected_sheet = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Sheet:", file_info['sheets'], key=f"merger_sheet_{filename}", disabled=not is_selected)
                            selected_sheets[filename] = selected_sheet
                        else:
                            selected_sheets[filename] = file_info['sheets'][0]
                            st.info(f"Sheet: {file_info['sheets'][0]}")
                    if is_selected:
                        sheet_name = selected_sheets[filename]
                        if sheet_name in file_info['data']:
                            df = file_info['data'][sheet_name]
                            st.write(f"**Preview ({len(df)} ‡πÅ‡∏ñ‡∏ß, {len(df.columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå):**")
                            st.dataframe(df.head(5), use_container_width=True)
        with cols[1]:
            selected_files_data = {k: v for k, v in st.session_state.merger_processed_data.items() if st.session_state.merger_selected_files.get(k, True)}
            total_files = len(selected_files_data)
            total_records = sum([
                len(file_info['data'][selected_sheets.get(filename, file_info['sheets'][0])]) 
                for filename, file_info in selected_files_data.items()
                if selected_sheets.get(filename, file_info['sheets'][0]) in file_info['data']
            ]) if selected_files_data else 0
            st.markdown(f"""<div class="metric-card"><h3>üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥</h3><p><strong>‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:</strong> {total_files}</p><p><strong>‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏£‡∏ß‡∏°:</strong> {total_records:,}</p></div>""", unsafe_allow_html=True)

        st.header("üîç ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Headers")
        all_headers, has_mismatch, file_headers = merger.analyze_headers(st.session_state.merger_processed_data, selected_sheets, st.session_state.merger_selected_files)
        if has_mismatch and len(file_headers) > 1:
            st.warning("‚ö†Ô∏è ‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á Headers")
            for filename, headers in file_headers.items():
                with st.expander(f"Headers ‡∏Ç‡∏≠‡∏á {filename}"):
                    st.write(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô:** {len(headers)} headers")
                    st.write(", ".join(headers))
            st.info("üí° ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ Headers ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á")
        elif len(file_headers) > 1:
            st.success("‚úÖ Headers ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô")

        st.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå")
        if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå", type="primary", use_container_width=True, key="merge_files_btn"):
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå..."):
                merged_df = merger.merge_files(st.session_state.merger_processed_data, selected_sheets, st.session_state.merger_selected_files)
                st.session_state.merger_merged_df = merged_df
                st.success(f"‚úÖ ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! {len(merged_df):,} ‡πÅ‡∏ñ‡∏ß")

        # ===== ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ =====
        def analyze_duplicates(df: pd.DataFrame):
            if df.empty:
                return pd.DataFrame(), 0
            dup_mask = df.duplicated(keep=False)
            dup_df = df[dup_mask].copy()
            return dup_df, dup_mask.sum()
        
        
        # ===== ‡∏™‡πà‡∏ß‡∏ô render_merger_tab (‡∏´‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏£‡πá‡∏à) =====
        if st.session_state.merger_merged_df is not None:
            st.header("üìä ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå")
        
            # ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å session
            merged_df = st.session_state.merger_merged_df.copy()
        
            # ‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥
            dup_df, dup_count = analyze_duplicates(merged_df)
        
            if dup_count > 0:
                st.warning(f"‚ö†Ô∏è ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ {dup_count:,} ‡πÅ‡∏ñ‡∏ß ‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(merged_df):,}")
                with st.expander("üîç ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥"):
                    st.dataframe(dup_df.head(10), use_container_width=True)
        
                action = st.radio(
                    "‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?",
                    ["‚ùå ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥", "‚û°Ô∏è ‡∏Ç‡πâ‡∏≤‡∏° (‡∏Ñ‡∏á‡πÑ‡∏ß‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)"],
                    horizontal=True,
                    key="dup_action"
                )
        
                if action == "‚ùå ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥":
                    merged_df = merged_df.drop_duplicates(keep="first").reset_index(drop=True)
                    st.success(f"‚úÖ ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ {len(merged_df):,} ‡πÅ‡∏ñ‡∏ß")
                else:
                    st.info("üìé ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏ß‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏•‡∏ö‡∏ã‡πâ‡∏≥")
        
                # ‚úÖ highlight duplicates ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏•‡∏ö
                if action == "‚û°Ô∏è ‡∏Ç‡πâ‡∏≤‡∏° (‡∏Ñ‡∏á‡πÑ‡∏ß‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)":
                    dup_mask = merged_df.duplicated(keep=False)
        
                    def highlight_duplicates(row):
                        idx = row.name
                        return ['background-color: #ffe6e6' if dup_mask.iloc[idx] else '' for _ in row]
        
                    st.dataframe(
                        merged_df.style.apply(highlight_duplicates, axis=1),
                        use_container_width=True
                    )
                else:
                    st.dataframe(merged_df.head(100), use_container_width=True)
            else:
                st.success("‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥")
                st.dataframe(merged_df.head(100), use_container_width=True)
        
            # ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ session
            st.session_state.merger_merged_df = merged_df

        



            st.header("‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î")
            d1, d2 = st.columns([1,2])
            with d1:
                download_format = st.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå:", options=["CSV", "Excel (XLSX)"], index=0, key="download_format")
            with d2:
                if download_format == "CSV":
                    filename = f"merged_file_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                    csv_data = merged_df.to_csv(index=False, encoding='utf-8-sig')
                    file_size = len(csv_data.encode('utf-8')) / 1024
                    st.info(f"üìÑ CSV | ‡∏Ç‡∏ô‡∏≤‡∏î: {file_size:.2f} KB")
                    st.download_button(label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV", data=csv_data, file_name=filename, mime="text/csv", type="primary", use_container_width=True, key="download_merged_csv")
                else:
                    filename = f"merged_file_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        merged_df.to_excel(writer, index=False, sheet_name='Merged Data')
                        worksheet = writer.sheets['Merged Data']
                        for column in worksheet.columns:
                            max_length = 0
                            column_letter = column[0].column_letter
                            for cell in column:
                                try:
                                    if len(str(cell.value)) > max_length:
                                        max_length = len(str(cell.value))
                                except:
                                    pass
                            adjusted_width = min(max_length + 2, 50)
                            worksheet.column_dimensions[column_letter].width = adjusted_width
                        worksheet.auto_filter.ref = worksheet.dimensions
                    excel_data = output.getvalue()
                    file_size = len(excel_data) / 1024
                    st.info(f"üìä Excel | ‡∏Ç‡∏ô‡∏≤‡∏î: {file_size:.2f} KB")
                    st.download_button(label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel", data=excel_data, file_name=filename, mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", type="primary", use_container_width=True, key="download_merged_excel")
    else:
        st.info("üëÜ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

import re
import time
from datetime import datetime
import streamlit as st
import pandas as pd
import mysql.connector

def render_data_editor_tab():
    # === DATABASE CONNECTION ===
    if 'db_manager' not in st.session_state:
        st.session_state.db_manager = DatabaseManager()
    db = st.session_state.db_manager

    # === TABLE SELECTION PANEL ===
    st.markdown("### üìÇ Select Target Table")
    try:
        tables_info = get_cached_tables_info()
        tables = [t['TABLE_NAME'] for t in tables_info] if tables_info else []

        HIDDEN_TABLES = ["user_permissions", "sn"]
        tables = [t for t in tables if t not in HIDDEN_TABLES]
    except Exception as e:
        st.error(f"Cannot get tables: {e}")
        tables = []

    selected_table = st.selectbox("Select a table to view/edit", [""] + tables, key="table_selector")
    if not selected_table:
        st.info("üëÜ Please select a table to start.")
        return

    columns = [col['COLUMN_NAME'] for col in get_cached_table_columns(selected_table)]
    columns_lower = [c.lower() for c in columns]

    st.markdown("---")
    left, right = st.columns([1.2, 3])

    # ==========================================
    # üîç LEFT: SEARCH PANEL
    # ==========================================
    with left:
        st.markdown("#### üîç Smart Search")
        search_input = st.text_input(
            "Enter keywords or conditions",
            placeholder="‡πÄ‡∏ä‡πà‡∏ô service_type=FTTx , mm=‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°2025",
            key="search_input_field"
        )
        match_mode = st.radio("Match Mode", ["AND", "OR"], horizontal=True)
        row_limit_label = st.selectbox("Show rows", ["10", "100", "1000", "10000", "All"], index=0)
        row_limit = None if row_limit_label == "All" else int(row_limit_label)

        if st.button("üîÑ Refresh Data", use_container_width=True):
            st.cache_data.clear()
            st.experimental_rerun()

    # ==========================================
    # üìä RIGHT: DATA DISPLAY
    # ==========================================
    with right:
        # ---- Build SQL ----
        query = f"SELECT * FROM `{selected_table}`"
        params = []

        if search_input.strip():
            parts = [p.strip() for p in re.split('[,;]', search_input) if p.strip()]
            has_explicit_condition = any('=' in p for p in parts)

            if has_explicit_condition:
                conditions = []
                joiner = f" {match_mode} "
                for cond in parts:
                    if '=' in cond:
                        key, value = [x.strip() for x in cond.split('=', 1)]
                        if key.lower() in columns_lower:
                            real_col = columns[columns_lower.index(key.lower())]
                            conditions.append(f"`{real_col}` LIKE %s")
                            params.append(f"%{value}%")
                        else:
                            st.warning(f"‚ö†Ô∏è Column `{key}` not found ‚Äî ignored.")
                if conditions:
                    query += " WHERE " + joiner.join(conditions)
            else:
                like_clauses = f" {match_mode} ".join([f"`{col}` LIKE %s" for col in columns])
                query += f" WHERE {like_clauses}"
                params = [f"%{search_input}%"] * len(columns)

        if row_limit:
            query += f" LIMIT {row_limit}"

        with st.expander("üß† SQL Query Used", expanded=False):
            formatted_query = query
            for p in params:
                formatted_query = formatted_query.replace("%s", f"'{p}'", 1)
            st.code(formatted_query, language="sql")

        # ---- Load Data ----
        with st.spinner("üîé Searching database..."):
            try:
                df = db.execute_query(query, tuple(params))
                df = df.astype(str)  # ‚úÖ ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô string ‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
            except Exception as e:
                st.error(f"Query error: {e}")
                return

        if df is None or df.empty:
            st.warning("üì≠ No records found.")
            return

        st.success(f"‚úÖ Found {len(df)} records from `{selected_table}`")

        # ==========================================
        # üîê Authorization
        # ==========================================
        st.markdown("#### üîê Authorization (optional)")
        
        secret_key = st.text_input(
            "Enter Secret Key (optional)",
            type="password",
            placeholder="Enter your key for edit permission",
            key="auth_key_editor"
        )
        
        user_perm = get_user_permission(secret_key)
        if not user_perm:
            st.info("üëÅ Showing only first 10 rows (Guest access).")
            username, user_role, is_authorized, can_edit = "Guest", "Guest", False, False
        else:
            username = secret_key.strip()
            user_role = user_perm["role"]
            is_authorized = True
            allowed_edit = user_perm.get("allowed_edit_tables", [])
            if user_role == "Admin" or selected_table in allowed_edit:
                st.success(f"‚úÖ Authorized as {user_role} (Edit Enabled)")
                can_edit = True
            else:
                st.warning(f"üö´ You can view but not edit `{selected_table}`.")
                can_edit = False
        
        # --- ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ---
        if not is_authorized:
            display_df = df.head(10)
        else:
            display_df = df
        
        # --- Editor ---
        st.markdown("### üßÆ Data Viewer & Editor")
        # ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏£‡∏Ñ‡∏Ñ‡∏≠‡∏£‡πå‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÅ‡∏•‡∏∞‡∏°‡∏µ emoji ‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏á‡πà‡∏≤‡∏¢)
        if display_df is not None and not display_df.empty:
            record_count = len(display_df)
            st.caption(f"üìä **Total records:** {record_count:,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        else:
            st.caption("‚ö†Ô∏è No data available to display.")
        edited_df = st.data_editor(
            display_df,
            num_rows="dynamic",
            use_container_width=True,
            key="data_editor_panel",
            hide_index=True,
            disabled=not can_edit   # ‚úÖ ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå
        )


        # ==========================================
        # üíæ Detect Changes (only if authorized)
        # ==========================================
        if not edited_df.equals(display_df):
            if not is_authorized:
                st.warning("üîí Editing disabled ‚Äî enter valid key for edit privileges.", icon="üîë")
            else:
                st.info("üìù Detected unsaved changes!")

                pk_col = next((c for c in ['id', 'ID', 'Ticketno','Ticket No', 'ticket_no', 'no', 'No'] if c in columns), None)
                if not pk_col:
                    st.error("‚ö†Ô∏è Cannot find primary key column.")
                    return

                update_queries, update_params, affected_keys = [], [], []
                for i, row in edited_df.iterrows():
                    if i < len(display_df) and not row.equals(display_df.iloc[i]):
                        set_clause = ", ".join([f"`{c}`=%s" for c in columns if c != pk_col])
                        update_query = f"UPDATE `{selected_table}` SET {set_clause} WHERE `{pk_col}`=%s"
                        vals = [row[c] for c in columns if c != pk_col] + [row[pk_col]]
                        update_queries.append(update_query)
                        update_params.append(vals)
                        affected_keys.append(row[pk_col])

                # ‚úÖ SQL Preview ‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
                with st.expander("üß© SQL Preview (before saving)", expanded=True):
                    for i, q in enumerate(update_queries):
                        formatted_sql = q.replace("%s", "'{}'").format(*[str(v) for v in update_params[i]])
                        st.code(formatted_sql, language="sql")

                confirm = st.checkbox("‚úÖ Confirm update queries before saving", key="confirm_update")

                if st.button("üíæ Save Changes", type="primary", use_container_width=True, disabled=not confirm):
                    try:
                        with st.spinner("üíæ Applying changes..."):
                            conn = db.get_connection()
                            cursor = conn.cursor()
                            for q, vals in zip(update_queries, update_params):
                                cursor.execute(q, vals)
                            conn.commit()
                            cursor.close()
                            conn.close()

                        # ‚úÖ Log Activity (‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å username ‡∏à‡∏£‡∏¥‡∏á)
                        try:
                            log_conn = db.get_connection()
                            log_cursor = log_conn.cursor()

                            # ‚úÖ ‡∏£‡∏ß‡∏° SQL ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô details
                            executed_sql = "\n".join([
                                q.replace("%s", "'{}'").format(*[str(v) for v in vals])
                                for q, vals in zip(update_queries, update_params)
                            ])
                            if len(executed_sql) > 2000:  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ö‡∏ß‡∏°
                                executed_sql = executed_sql[:2000] + " ... (truncated)"
                        
                            details_text = f"rows={len(affected_keys)}\n{executed_sql}"
                        
                            log_cursor.execute("""
                                INSERT INTO activity_log (username, action, target, ip_address, details)
                                VALUES (%s, %s, %s, %s, %s)
                            """, (
                                username,
                                "Edit Data",
                                selected_table,
                                st.session_state.get('client_ip', 'unknown'),
                                details_text
                            ))

                            log_conn.commit()
                            log_cursor.close()
                            log_conn.close()
                        except Exception as log_err:
                            st.warning(f"‚ö†Ô∏è Failed to write log: {log_err}")

                        st.success("‚úÖ Data updated successfully.")
                        st.toast("üíæ Changes saved!", icon="‚úÖ")

                        # ‚úÖ ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ table LK_Broadband_daily
                        if selected_table == "LK_Broadband_daily":
                            st.markdown("""
                            <div style="margin-top:10px; padding:10px; border-left:4px solid #f39c12; background-color:#fffbea;">
                                ‚ö†Ô∏è <b>‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà Looker Studio</b><br>
                                üëâ <a href="https://lookerstudio.google.com/reporting/1483b6e3-3477-4906-8966-ec276423ec27" target="_blank" style="color:#0073e6; text-decoration:none;">
                                ‡πÄ‡∏õ‡∏¥‡∏î‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Dashboard</a>
                            </div>
                            """, unsafe_allow_html=True)

                    except Exception as e:
                        st.error(f"‚ùå Update failed: {e}")

        # ==========================================
        # üìä Data Display & Download
        # ==========================================
        st.markdown("---")
        st.caption("üí° Use the built-in download icon on top-right to export the visible data.")

        # ‚úÖ Log full access (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ authorized)
        if is_authorized and secret_key.strip():
            try:
                conn = db.get_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO activity_log (username, action, target, ip_address, details)
                    VALUES (%s, %s, %s, %s, %s)
                """, (
                    username,
                    "View Full Data",
                    selected_table,
                    st.session_state.get('client_ip', 'unknown'),
                    f"rows={len(df)}"
                ))
                conn.commit()
                cursor.close()
                conn.close()
                st.toast("üìú Logged: Full view access", icon="‚úÖ")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Log failed: {e}")

        # ==========================================
        # üìÖ Footer
        # ==========================================
        st.markdown("---")
        st.caption(f"üìÖ Last refreshed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")




def render_log_tab():
    st.header("üìú Activity Log")

    db = st.session_state.db_manager

    # ---- Filter Controls ----
    with st.expander("üîç Filter Logs", expanded=False):
        cols = st.columns(4)
        with cols[0]:
            search_action = st.text_input("Action", placeholder="‡πÄ‡∏ä‡πà‡∏ô Import Data, Edit Data")
        with cols[1]:
            search_target = st.text_input("Target", placeholder="‡πÄ‡∏ä‡πà‡∏ô datacomNT, LK_Ticket")
        with cols[2]:
            search_user = st.text_input("Username", placeholder="‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô")
        with cols[3]:
            limit_per_page = st.selectbox("Rows per page", [50, 100, 200, 500], index=1)

    # ---- Build SQL dynamically ----
    where_clauses = []
    params = []
    if search_action:
        where_clauses.append("action LIKE %s")
        params.append(f"%{search_action}%")
    if search_target:
        where_clauses.append("target LIKE %s")
        params.append(f"%{search_target}%")
    if search_user:
        where_clauses.append("username LIKE %s")
        params.append(f"%{search_user}%")

    where_sql = f"WHERE {' AND '.join(where_clauses)}" if where_clauses else ""

    # ---- Count total rows ----
    count_query = f"SELECT COUNT(*) as total FROM activity_log {where_sql}"
    count_df = db.execute_query(count_query, tuple(params))
    total_rows = int(count_df.iloc[0]['total']) if (count_df is not None and not count_df.empty) else 0

    # ---- Pagination ----
    page_count = max(1, (total_rows + limit_per_page - 1) // limit_per_page)
    current_page = st.number_input("üìÑ Page", min_value=1, max_value=page_count, step=1, value=1)
    offset = (current_page - 1) * limit_per_page

    # ---- Query data ----
    query = f"""
        SELECT * FROM activity_log
        {where_sql}
        ORDER BY timestamp DESC
        LIMIT %s OFFSET %s
    """
    df = db.execute_query(query, tuple(params + [limit_per_page, offset]))

    # ---- Username masking ----
    def mask_username(name: str):
        """‡∏ã‡πà‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á username a********u'"""
        if not name or not isinstance(name, str):
            return ""
        if len(name) <= 2:
            return name[0] + "**" if len(name) == 2 else name
        return name[0] + "**" * (len(name) - 2) + name[-1]

    if df is not None and not df.empty:
        df = df.copy()

        # ‚úÖ Mask username
        if "username" in df.columns:
            df["username"] = df["username"].apply(mask_username)

        # ‚úÖ Hide ID column if exists
        if "id" in df.columns:
            df = df.drop(columns=["id"])

        # ‚úÖ Format timestamp (optional)
        if "timestamp" in df.columns:
            df["timestamp"] = pd.to_datetime(df["timestamp"]).dt.strftime("%Y-%m-%d %H:%M:%S")

        # ---- Display Data ----
        try:
            # ‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÉ‡∏ô Streamlit ‚â• 1.36
            st.dataframe(
                df,
                use_container_width=True,
                hide_index=True,
                hide_download_button=True  # ‡∏õ‡∏¥‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
            )
        except TypeError:
            # ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Streamlit < 1.36 (‡πÑ‡∏°‡πà‡∏°‡∏µ argument ‡∏ô‡∏µ‡πâ)
            st.dataframe(
                df,
                use_container_width=True,
                hide_index=True
            )
        
        # ‚úÖ ‡∏ã‡πà‡∏≠‡∏ô‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏î‡πâ‡∏ß‡∏¢ CSS (backup)
        # ---- ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å st.dataframe(df, ...) ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏™‡πà CSS ‡∏ô‡∏µ‡πâ ----
        st.markdown("""
        <style>
        /* Streamlit DataFrame / Data Editor download buttons */
        [data-testid="stElementToolbar"] button[aria-label*="Download"] {
            display: none !important;
        }
        button[title="Download data as CSV"],
        button[aria-label="Download data as CSV"],
        button[aria-label="Download"] {
            display: none !important;
        }
        </style>
        """, unsafe_allow_html=True)



        # ---- Navigation Buttons ----
        c1, c2, c3 = st.columns([1, 1, 6])
        with c1:
            if st.button("‚¨ÖÔ∏è Previous", disabled=(current_page <= 1)):
                st.session_state["log_page"] = current_page - 1
                st.experimental_rerun()
        with c2:
            if st.button("‚û°Ô∏è Next", disabled=(current_page >= page_count)):
                st.session_state["log_page"] = current_page + 1
                st.experimental_rerun()

    else:
        st.info("üì≠ No activity logs found.")

  
    # ---- Optional: summary chart ----
    import altair as alt
    
    with st.expander("üìä Log Summary Chart", expanded=False):
        try:
            agg_query = """
                SELECT DATE(timestamp) AS date, COUNT(*) AS count
                FROM activity_log
                GROUP BY DATE(timestamp)
                ORDER BY date ASC
                LIMIT 14
            """
            agg_df = db.execute_query(agg_query)
    
            if agg_df is not None and not agg_df.empty:
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ date ‡πÄ‡∏õ‡πá‡∏ô datetime
                agg_df["date"] = pd.to_datetime(agg_df["date"])
    
                chart = (
                    alt.Chart(agg_df)
                    .mark_bar(size=25, color="#2563eb")  # ‚úÖ ‡∏Ç‡∏ô‡∏≤‡∏î‡πÅ‡∏ó‡πà‡∏á + ‡∏™‡∏µ
                    .encode(
                        x=alt.X("date:T", title="‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", axis=alt.Axis(labelAngle=-45)),
                        y=alt.Y("count:Q", title="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°"),
                        tooltip=["date:T", "count:Q"]
                    )
                    .properties(
                        width="container",
                        height=300,
                        title="üìÖ Log Summary (14 Days)"
                    )
                )
                st.altair_chart(chart, use_container_width=True)
            else:
                st.info("‚ÑπÔ∏è No log data available.")
        except Exception as e:
            st.warning(f"Chart load failed: {e}")


# ==========================================
# üîê USER PERMISSIONS LOADER & ACCESS CHECK
# ==========================================
def load_user_permissions(db):
    """‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á user_permissions"""
    try:
        df = db.execute_query("""
            SELECT username, role, allowed_tables, allowed_procedures, allowed_edit_tables
            FROM user_permissions
        """)
        if df is None or df.empty:
            return {}
        perms = {}
        for _, row in df.iterrows():
            perms[row['username']] = {
                "role": row['role'],
                "allowed_tables": [t.strip() for t in (row['allowed_tables'] or '').split(',') if t.strip()],
                "allowed_procedures": [p.strip() for p in (row['allowed_procedures'] or '').split(',') if p.strip()],
                "allowed_edit_tables": [e.strip() for e in (row['allowed_edit_tables'] or '').split(',') if e.strip()],
            }
        return perms
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Cannot load user permissions: {e}")
        return {}

def get_user_permission(secret_key: str):
    """‡∏î‡∏∂‡∏á‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å session_state.user_permissions ‡∏ï‡∏≤‡∏° secret_key"""
    key = secret_key.strip()
    if not key:
        return None

    # ‡∏î‡∏∂‡∏á dict ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å session
    user_perms = st.session_state.get('user_permissions', {})

    # ‡∏ñ‡πâ‡∏≤ key ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô session ‚Äî ‡∏Ñ‡∏∑‡∏ô None ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
    if key not in user_perms:
        return None

    perm = user_perms[key]

    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ field 'username'
    # (‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡πÅ‡∏ï‡πà role / allowed_procedures)
    username = perm.get("username") or perm.get("user") or key

    # ‚úÖ ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏° fallback
    return {
        "username": username,
        "role": perm.get("role", "Viewer"),
        "allowed_tables": perm.get("allowed_tables", []),
        "allowed_procedures": perm.get("allowed_procedures", []),
        "allowed_edit_tables": perm.get("allowed_edit_tables", []),
    }


# ==========================================
# üîë KEY MANAGEMENT TAB (ADMIN ONLY)
# ==========================================
def render_user_management_tab():
    st.markdown("## üîë Key Management")
    st.caption("‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏£‡∏∞‡∏ö‡∏ö ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏Å‡∏£‡∏´‡∏±‡∏™‡∏•‡∏±‡∏ö (Secret Key)")

    # ===== Authorization =====
    secret_key = st.text_input(
        "Enter Secret Key",
        type="password",
        placeholder="Enter your key",
        key="user_mgmt_key"
    ).strip()

    user_perm = get_user_permission(secret_key)

    if not user_perm:
        st.warning("üö´ Access denied. Invalid or missing key.")
        st.stop()

    role = user_perm["role"]
    username = user_perm.get("username", "(unknown)")

    db = st.session_state.db_manager

    # ===== Role-based Display =====
    if role == "Admin":
        st.success(f"‚úÖ Authorized as **Admin** ‚Äî full access ({username})")

        try:
            df = db.execute_query("SELECT * FROM user_permissions ORDER BY role, username")
        except Exception as e:
            st.error(f"Cannot load users: {e}")
            return

        st.markdown("### üìã Current Users (Editable)")
        edited_df = st.data_editor(
            df,
            num_rows="dynamic",
            use_container_width=True,
            key="user_editor",
            hide_index=True
        )

        # --- ‡∏õ‡∏∏‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ---
        if st.button("üíæ Save Changes to Database", type="primary"):
            try:
                db.execute_nonquery("DELETE FROM user_permissions")
                for _, row in edited_df.iterrows():
                    query = """
                        INSERT INTO user_permissions
                        (id, username, role, allowed_tables, allowed_procedures, allowed_edit_tables, created_at, updated_at)
                        VALUES (%s,%s,%s,%s,%s,%s,NOW(),NOW())
                    """
                    params = (
                        int(row["id"]) if not pd.isna(row["id"]) else None,
                        row["username"],
                        row["role"],
                        row.get("allowed_tables", None),
                        row.get("allowed_procedures", None),
                        row.get("allowed_edit_tables", None)
                    )
                    db.execute_nonquery(query, params)
                st.success("‚úÖ User permissions updated successfully!")
                st.session_state.user_permissions = load_user_permissions(db)
            except Exception as e:
                st.error(f"‚ùå Failed to update users: {e}")

        # --- ‡∏ü‡∏≠‡∏£‡πå‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏´‡∏°‡πà (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Admin) ---
        with st.expander("‚ûï Add New User"):
            with st.form("add_user_form", clear_on_submit=True):
                cols = st.columns(2)
                with cols[0]:
                    new_username = st.text_input("Username", placeholder="‡πÄ‡∏ä‡πà‡∏ô adcharaporn.u")
                    new_role = st.selectbox("Role", ["Viewer", "Operator", "Admin"])
                with cols[1]:
                    allowed_tables = st.text_input("Allowed Tables (comma-separated)")
                    allowed_procs = st.text_input("Allowed Procedures (comma-separated)")
                    allowed_edit = st.text_input("Allowed Edit Tables (comma-separated)")

                submitted = st.form_submit_button("Add User")
                if submitted:
                    try:
                        query = """
                            INSERT INTO user_permissions
                            (username, role, allowed_tables, allowed_procedures, allowed_edit_tables)
                            VALUES (%s,%s,%s,%s,%s)
                        """
                        db.execute_nonquery(query, (new_username, new_role, allowed_tables, allowed_procs, allowed_edit))
                        st.success(f"‚úÖ Added new user: {new_username}")
                        st.session_state.user_permissions = load_user_permissions(db)
                    except Exception as e:
                        st.error(f"‚ùå Failed to add user: {e}")

    elif role == "Operator":
        st.warning(f"üë∑ Authorized as **Operator** ‚Äî view-only mode ({username})")

        try:
            df = db.execute_query(
                "SELECT * FROM user_permissions WHERE username = %s", (username,)
            )
        except Exception as e:
            st.error(f"Cannot load your data: {e}")
            return

        st.markdown("### üìã Your Information (View Only)")
        st.dataframe(df, use_container_width=True, hide_index=True)
        st.info("‚ÑπÔ∏è You cannot add or edit user data in Operator mode.")

    else:
        st.warning(f"‚ö†Ô∏è Role `{role}` has no access to this section.")
        st.stop() 
# ===== MAIN APPLICATION =====
def main():
    try:
        st.markdown("""
        <div class="main-header">
            <h1>üöÄ Database Management Hub</h1>
            <p>Complete database management system with import, procedures, update and file merger</p>
        </div>
        """, unsafe_allow_html=True)

        if 'client_ip' not in st.session_state:
            try:
                import requests
                st.session_state['client_ip'] = requests.get('https://api.ipify.org').text
            except:
                st.session_state['client_ip'] = 'unknown'
        if 'db_manager' not in st.session_state:
            try:
                st.session_state.db_manager = DatabaseManager()
            except Exception as e:
                st.error(f"Failed to initialize DatabaseManager: {e}")
                return
        if 'file_processor' not in st.session_state:
            try:
                st.session_state.file_processor = FileProcessor()
            except Exception as e:
                st.error(f"Failed to initialize FileProcessor: {e}")
                return
        # ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
        if 'user_permissions' not in st.session_state:
            st.session_state.user_permissions = load_user_permissions(st.session_state.db_manager)


        with st.sidebar:
            # === CONFIGURATION SECTION ===
            st.header("‚öôÔ∏è Configuration")
            if 'connection_status' not in st.session_state:
                try:
                    st.session_state.connection_status = st.session_state.db_manager.test_connection()
                except Exception:
                    st.session_state.connection_status = False
        
            if st.session_state.connection_status:
                st.markdown('<div class="status-success">‚úÖ Database Connected</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="status-error">‚ùå Database Connection Failed</div>', unsafe_allow_html=True)
        
            if st.button("üîÑ Refresh", key="refresh_sidebar"):
                st.cache_data.clear()
                st.rerun()
        
            try:
                tables_info = get_cached_tables_info()
                tables = [table['TABLE_NAME'] for table in tables_info] if tables_info else []
            except Exception:
                tables = []
                tables_info = []
        
            st.write(f"üìä Available Tables: {len(tables)}")
        
            # === SMART AI ASSISTANT ===
            st.markdown("---")
            st.subheader("üß† Smart AI Assistant")
            st.caption("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
            user_query = st.text_area(
                "üí¨ Ask AI",
                placeholder="‡πÄ‡∏ä‡πà‡∏ô ‚Äú‡πÅ‡∏™‡∏î‡∏á 5 ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‚Äù ‡∏´‡∏£‡∏∑‡∏≠ ‚ÄúSQL ‡∏´‡∏≤‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á datacomNT‚Äù",
                key="ai_assistant_query",
                height=80
            )
        
            if st.button("üöÄ Analyze with AI", use_container_width=True):
                if not user_query.strip():
                    st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô", icon="üí°")
                else:
                    with st.spinner("ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
                        # Mockup AI Response (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏à‡∏£‡∏¥‡∏á)
                        st.success("‚ú® AI Suggestion:")
                        st.write("```sql\nSELECT * FROM datacomNT ORDER BY timestamp DESC LIMIT 5;\n```")
                        st.caption("üí° ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á SQL ‡∏ó‡∏µ‡πà AI ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥")
        
            # === RECENT ACTIVITY ===
            st.markdown("---")
            st.subheader("üïì Recent Activity")
        
            try:
                db = st.session_state.get('db_manager')
                if db:
                    df_log = db.execute_query("""
                        SELECT username, action, target, timestamp
                        FROM activity_log
                        ORDER BY timestamp DESC
                        LIMIT 5
                    """)
                else:
                    df_log = None
            except Exception as e:
                df_log = None
                st.warning(f"‚ö†Ô∏è Cannot load activity log: {e}")
        
            if df_log is not None and not df_log.empty:
                # ‡∏ã‡πà‡∏≠‡∏ô username ‡∏Å‡∏•‡∏≤‡∏á
                def mask_username(name: str):
                    if not name or not isinstance(name, str): return ""
                    if len(name) <= 2: return name[0] + "*" if len(name) == 2 else name
                    return name[0] + "*" * (len(name) - 2) + name[-1]
        
                df_log["username"] = df_log["username"].apply(mask_username)
                for _, row in df_log.iterrows():
                    st.markdown(
                        f"‚Ä¢ **{row['action']}** ‚Üí `{row['target']}`  \n"
                        f"<span style='color:gray;font-size:0.85em;'>üë§ {row['username']} ‚Äî üïí {row['timestamp']}</span>",
                        unsafe_allow_html=True
                    )
            else:
                st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î")
        
            # === STYLING ===
            st.markdown("""
            <style>
            [data-testid="stSidebar"] {
                background: linear-gradient(180deg, #f9fafc 0%, #eef1f9 100%);
                padding: 1rem 1.2rem;
                font-family: 'Sarabun', sans-serif;
            }
            [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3, [data-testid="stSidebar"] h4 {
                color: #3b3b98;
            }
            [data-testid="stSidebar"] button {
                border-radius: 8px !important;
            }
            </style>
            """, unsafe_allow_html=True)


        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([ "üìÅ Import Data", "‚öôÔ∏è Run Procedures","üßæ View & Edit Data","üîó File Merger","üìú Logs","üîë Key Management"])
        with tab1:
            render_import_tab()
        with tab2:
            render_procedures_tab()
        with tab3:
            render_data_editor_tab()  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà
        with tab4:
            render_merger_tab() 
        with tab5:
            render_log_tab()
        with tab6:
            render_user_management_tab()
    except Exception as e:
        st.error(f"Application error: {e}")

if __name__ == "__main__":
    main()
