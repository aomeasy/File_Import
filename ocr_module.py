#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Thai OCR with PDF Support
‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á PDF ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û
"""

import cv2
import numpy as np
import pytesseract
from PIL import Image, ImageEnhance
import re
import os

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PDF
try:
    import PyPDF2
    import fitz  # PyMuPDF
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False
    print("‚ö†Ô∏è  PDF libraries not installed. Install with:")
    print("   pip install PyPDF2 PyMuPDF")

class EnhancedThaiDocumentOCR:
    def __init__(self):
        self.thai_digits = {
            '0': '‡πê', '1': '‡πë', '2': '‡πí', '3': '‡πì', '4': '‡πî',
            '5': '‡πï', '6': '‡πñ', '7': '‡πó', '8': '‡πò', '9': '‡πô'
        }
    
    def check_pdf_has_text(self, pdf_path):
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ PDF ‡∏°‡∏µ text layer ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        """
        if not PDF_SUPPORT:
            return False
        
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö 3 ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å
                pages_to_check = min(3, len(pdf_reader.pages))
                
                for i in range(pages_to_check):
                    page = pdf_reader.pages[i]
                    text = page.extract_text()
                    
                    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÑ‡∏ó‡∏¢‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50 ‡∏ï‡∏±‡∏ß ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏°‡∏µ text layer
                    thai_chars = len(re.findall(r'[‡∏Å-‡∏Æ‡∏∞-‡πå]', text))
                    if thai_chars > 50:
                        return True
                
                return False
                
        except Exception as e:
            print(f"Error checking PDF: {e}")
            return False
    
    def extract_text_from_pdf(self, pdf_path):
        """
        Extract text ‡∏à‡∏≤‡∏Å PDF ‡∏ó‡∏µ‡πà‡∏°‡∏µ text layer
        """
        if not PDF_SUPPORT:
            raise ImportError("PyPDF2 not installed")
        
        print("‚úì PDF has text layer - extracting directly...")
        
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                
                all_text = []
                for i, page in enumerate(pdf_reader.pages):
                    print(f"  Page {i+1}/{len(pdf_reader.pages)}")
                    text = page.extract_text()
                    all_text.append(text)
                
                combined_text = '\n\n'.join(all_text)
                return combined_text
                
        except Exception as e:
            print(f"‚úó Error extracting text: {e}")
            return None
    
    def pdf_to_images(self, pdf_path, output_folder='temp_pages', dpi=300):
        """
        ‡πÅ‡∏õ‡∏•‡∏á PDF ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PDF ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ text layer)
        """
        if not PDF_SUPPORT:
            raise ImportError("PyMuPDF not installed")
        
        print(f"Converting PDF to images (DPI={dpi})...")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á folder
        os.makedirs(output_folder, exist_ok=True)
        
        try:
            doc = fitz.open(pdf_path)
            image_paths = []
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                
                # Render page ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û (DPI ‡∏™‡∏π‡∏á!)
                zoom = dpi / 72  # 72 is default DPI
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat, alpha=False)
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô PNG
                output_path = os.path.join(output_folder, f'page_{page_num+1}.png')
                pix.save(output_path)
                image_paths.append(output_path)
                
                print(f"  ‚úì Page {page_num+1}/{len(doc)} saved: {output_path}")
            
            doc.close()
            return image_paths
            
        except Exception as e:
            print(f"‚úó Error converting PDF: {e}")
            return []
    
    def preprocess_for_low_quality(self, image_path):
        """
        Preprocessing ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≥
        """
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Cannot read image: {image_path}")
        
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Resize
        height, width = gray.shape
        target_height = 3500
        if height < target_height:
            scale = target_height / height
            new_width = int(width * scale)
            new_height = int(height * scale)
            gray = cv2.resize(gray, (new_width, new_height), 
                            interpolation=cv2.INTER_LANCZOS4)
        
        # Bilateral filter + Denoise
        bilateral = cv2.bilateralFilter(gray, 9, 75, 75)
        denoised = cv2.fastNlMeansDenoising(bilateral, None, h=20, 
                                            templateWindowSize=7, 
                                            searchWindowSize=21)
        
        # Sharpen
        kernel_sharpen = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
        sharpened = cv2.filter2D(denoised, -1, kernel_sharpen)
        
        # CLAHE
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(sharpened)
        
        # Unsharp masking
        gaussian = cv2.GaussianBlur(enhanced, (0, 0), 2.0)
        unsharp = cv2.addWeighted(enhanced, 1.5, gaussian, -0.5, 0)
        
        # Adaptive thresholding
        binary = cv2.adaptiveThreshold(unsharp, 255, 
                                       cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                       cv2.THRESH_BINARY, 
                                       blockSize=21, C=2)
        
        # Morphological operations
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
        
        return binary
    
    def preprocess_for_high_quality(self, image_path):
        """
        Preprocessing ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å PDF (‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á)
        ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á aggressive ‡∏°‡∏≤‡∏Å
        """
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Cannot read image: {image_path}")
        
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Resize (‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
        height, width = gray.shape
        if height < 2500:
            scale = 2500 / height
            new_width = int(width * scale)
            new_height = int(height * scale)
            gray = cv2.resize(gray, (new_width, new_height), 
                            interpolation=cv2.INTER_CUBIC)
        
        # Denoise ‡πÄ‡∏ö‡∏≤‡πÜ
        denoised = cv2.fastNlMeansDenoising(gray, None, h=10, 
                                            templateWindowSize=7, 
                                            searchWindowSize=21)
        
        # CLAHE
        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
        enhanced = clahe.apply(denoised)
        
        # Adaptive thresholding
        binary = cv2.adaptiveThreshold(enhanced, 255, 
                                       cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                       cv2.THRESH_BINARY, 
                                       blockSize=15, C=4)
        
        # Slight morphology
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        return binary
    
    def ocr_with_multiple_configs(self, image):
        """
        ‡∏•‡∏≠‡∏á OCR ‡∏´‡∏•‡∏≤‡∏¢ config
        """
        configs = [
            '--oem 1 --psm 6 -l tha',
            '--oem 1 --psm 4 -l tha',
            '--oem 1 --psm 3 -l tha',
            '--oem 3 --psm 6 -l tha',
            '--oem 1 --psm 11 -l tha',
        ]
        
        results = []
        for config in configs:
            try:
                text = pytesseract.image_to_string(image, config=config)
                data = pytesseract.image_to_data(image, config=config,
                                                output_type=pytesseract.Output.DICT)
                
                confs = [int(c) for c in data['conf'] if str(c) != '-1']
                avg_conf = sum(confs) / len(confs) if confs else 0
                thai_chars = len(re.findall(r'[‡∏Å-‡∏Æ‡∏∞-‡πå]', text))
                
                results.append({
                    'text': text,
                    'confidence': avg_conf,
                    'thai_chars': thai_chars,
                    'config': config
                })
                
            except Exception as e:
                pass
        
        if results:
            best = max(results, key=lambda x: x['confidence'] * 0.7 + x['thai_chars'] * 0.3)
            return best
        
        return None
    
    def post_process_thai_document(self, text):
        """
        Post-processing
        """
        result = text
        
        # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏ú‡∏¥‡∏î‡∏ö‡πà‡∏≠‡∏¢
      

        common_errors = {
            # üîπ ‡∏Ñ‡∏≥‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
            '‡∏Ñ‡∏ó‡∏∞': '‡∏Ñ‡∏ì‡∏∞', '‡∏ó‡∏ó': '‡∏ô‡∏±‡∏Å', '‡∏Å‡∏ó': '‡∏Å‡∏≥', '‡∏™‡∏≥‡∏ó‡∏ó': '‡∏™‡∏≥‡∏ô‡∏±‡∏Å',
            '‡πÄ‡∏£‡∏ó‡∏≠‡∏á': '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', '‡∏ß‡∏ó‡∏ó‡∏µ‡πà': '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ': '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà',
            '‡∏ñ‡∏ó': '‡∏ñ‡∏∂‡∏á', '‡∏≠‡∏ó‡∏á‡∏ñ‡∏ó': '‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á', '‡∏≠‡πâ ‡∏á‡∏ñ‡∏ó': '‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á',
            '‡∏Ñ ‡∏∞': '‡∏Ñ‡∏ì‡∏∞', '‡∏ó ‡∏á ‡∏ô': '‡∏ó‡∏≥‡∏á‡∏≤‡∏ô', '‡∏™ ‡∏á': '‡∏™‡πà‡∏á',
            '‡πÄ‡∏£‡∏ó ‡∏¢': '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô', '‡∏°‡∏´ ‡∏ß‡∏ó': '‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢',

            # üîπ ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏£‡∏∞ "‡∏≥" (OCR ‡∏°‡∏±‡∏Å‡∏≠‡πà‡∏≤‡∏ô‡∏ú‡∏¥‡∏î)
            '‡∏î‡∏≤‡πÄ‡∏ô‡∏¥‡∏ô': '‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô',
            '‡∏î‡∏≤‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£': '‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£',
            '‡∏î‡∏≤‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô': '‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î',
            '‡∏Å‡∏≤‡∏Å‡∏±‡∏ö': '‡∏Å‡∏≥‡∏Å‡∏±‡∏ö',
            '‡∏Å‡∏≤‡∏ä‡∏±‡∏ö': '‡∏Å‡∏≥‡∏ä‡∏±‡∏ö',
            '‡∏à‡∏≤‡∏ô‡∏ß‡∏ô': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô',
            '‡∏Å‡∏≤‡∏à‡∏±‡∏î': '‡∏Å‡∏≥‡∏à‡∏±‡∏î',
            '‡∏ô‡∏≤‡πÄ‡∏™‡∏ô‡∏≠': '‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠',
            '‡∏Å‡∏≤‡∏•‡∏±‡∏á': '‡∏Å‡∏≥‡∏•‡∏±‡∏á',
            '‡∏ó‡∏≤‡∏á‡∏≤‡∏ô': '‡∏ó‡∏≥‡∏á‡∏≤‡∏ô',
            '‡∏Å‡∏≤‡∏°‡∏∞‡∏•‡∏≠': '‡∏Å‡∏≥‡∏°‡∏∞‡∏•‡∏≠',
            '‡∏Å‡∏≤‡∏™‡∏£‡∏î': '‡∏Å‡∏≥‡∏™‡∏£‡∏î',
            '‡∏ó‡∏≤‡∏á‡∏≤‡∏ô': '‡∏ó‡∏≥‡∏á‡∏≤‡∏ô',
            '‡∏ó‡∏≤‡∏Å‡∏≤‡∏£': '‡∏ó‡∏≥‡∏Å‡∏≤‡∏£',
            '‡∏ó‡∏≤‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô': '‡∏ó‡∏≥‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô',
            '‡∏ó‡∏≤‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠': '‡∏ó‡∏≥‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠',
            '‡∏ó‡∏≤‡∏™‡∏±‡∏ç‡∏ç‡∏≤': '‡∏ó‡∏≥‡∏™‡∏±‡∏ç‡∏ç‡∏≤',
            '‡∏Ñ‡∏≤‡∏ô‡∏≥': '‡∏Ñ‡∏≥‡∏ô‡∏≥',
            '‡∏Ñ‡∏≤‡∏™‡∏±‡πà‡∏á': '‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á',
            '‡∏Ñ‡∏≤‡∏ä‡∏µ‡πâ‡πÅ‡∏à‡∏á': '‡∏Ñ‡∏≥‡∏ä‡∏µ‡πâ‡πÅ‡∏à‡∏á',
            '‡∏Ñ‡∏≤‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢': '‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢',
            '‡∏Ñ‡∏≤‡∏ï‡∏≠‡∏ö': '‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö',
            '‡∏Ñ‡∏≤‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥': '‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥',
            '‡∏Ñ‡∏≤‡∏£‡πâ‡∏≠‡∏á': '‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á',
            '‡∏Ñ‡∏≤‡∏Ç‡∏≠': '‡∏Ñ‡∏≥‡∏Ç‡∏≠',
            '‡∏Ñ‡∏≤‡∏Å‡∏•‡πà‡∏≤‡∏ß': '‡∏Ñ‡∏≥‡∏Å‡∏•‡πà‡∏≤‡∏ß',
            '‡∏Ñ‡∏≤‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤': '‡∏Ñ‡∏≥‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤',
            '‡∏™‡∏≤‡∏Ñ‡∏±‡∏ç': '‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç',
            '‡∏™‡∏≤‡πÄ‡∏£‡πá‡∏à': '‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à',
            '‡∏™‡∏≤‡∏´‡∏£‡∏±‡∏ö': '‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö',
            '‡∏™‡∏≤‡∏ô‡∏±‡∏Å': '‡∏™‡∏≥‡∏ô‡∏±‡∏Å',
            '‡∏™‡∏≤‡∏ô‡∏∂‡∏Å': '‡∏™‡∏≥‡∏ô‡∏∂‡∏Å',
            '‡∏™‡∏≤‡πÅ‡∏î‡∏á': '‡∏™‡∏≥‡πÅ‡∏î‡∏á',
            '‡∏™‡∏≤‡πÄ‡∏ô‡∏≤': '‡∏™‡∏≥‡πÄ‡∏ô‡∏≤',
            '‡∏™‡∏≤‡πÄ‡∏£‡πá‡∏à‡∏£‡∏π‡∏õ': '‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏£‡∏π‡∏õ',
            '‡∏™‡∏≤‡πÄ‡∏£‡πá‡∏à‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤': '‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤',
            '‡∏™‡∏≤‡πÄ‡∏£‡πá‡∏à‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£': '‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£',
            '‡∏™‡∏≤‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£': '‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£',
            '‡∏î‡∏≤‡∏£‡∏á': '‡∏î‡∏≥‡∏£‡∏á',
            '‡∏î‡∏≤‡∏£‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á': '‡∏î‡∏≥‡∏£‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á',
            '‡∏î‡∏≤‡∏£‡∏á‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï': '‡∏î‡∏≥‡∏£‡∏á‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï',
            '‡∏î‡∏≤‡∏£‡∏á‡∏ä‡∏µ‡∏û': '‡∏î‡∏≥‡∏£‡∏á‡∏ä‡∏µ‡∏û',
            '‡∏î‡∏≤‡∏£‡∏á‡∏≠‡∏¢‡∏π‡πà': '‡∏î‡∏≥‡∏£‡∏á‡∏≠‡∏¢‡∏π‡πà',
            '‡∏Å‡∏≤‡∏ô‡∏î': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î',  # OCR variant
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡πÄ‡∏ß‡∏•‡∏≤': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ß‡∏•‡∏≤',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡∏ß‡∏±‡∏ô': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡∏±‡∏ô',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡∏™‡πà‡∏á': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡πà‡∏á',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô',
            '‡∏™‡∏≤‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô': '‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô',
            '‡∏™‡∏≤‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤': '‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤',
            '‡∏™‡∏≤‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ': '‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ',
            '‡∏™‡∏≤‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà': '‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà',
            '‡∏™‡∏≤‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏á‡∏≤‡∏ô': '‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏á‡∏≤‡∏ô',
            '‡∏™‡∏≤‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£': '‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£',
            '‡∏™‡∏≤‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô': '‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ',
            '‡∏™‡∏≤‡πÄ‡∏ô‡∏≤‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô': '‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô',
            '‡∏™‡∏≤‡πÄ‡∏ô‡∏≤‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠': '‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠',
            '‡∏™‡∏≤‡πÄ‡∏ô‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£': '‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£',
            '‡∏™‡∏≤‡πÄ‡∏ô‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•': '‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•',
            '‡∏™‡∏≤‡πÄ‡∏ô‡∏≤‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô': '‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô',
            '‡∏™‡∏≤‡∏ô‡∏ß‡∏ô': '‡∏™‡∏≥‡∏ô‡∏ß‡∏ô',
            '‡∏™‡∏≤‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£': '‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£',
            '‡∏™‡∏≤‡∏ô‡∏ß‡∏ô‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢': '‡∏™‡∏≥‡∏ô‡∏ß‡∏ô',
            '‡∏Ñ‡∏≤‡πÅ‡∏ñ‡∏•‡∏á': '‡∏Ñ‡∏≥‡πÅ‡∏ñ‡∏•‡∏á',
            '‡∏Ñ‡∏≤‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á': '‡∏Ñ‡∏≥‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á',
            '‡∏Ñ‡∏≤‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô': '‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô',
            '‡∏Ñ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏': '‡∏Ñ‡∏≥‡∏£‡∏∞‡∏ö‡∏∏',
            '‡∏Ñ‡∏≤‡∏£‡∏±‡∏ö': '‡∏Ñ‡∏≥‡∏£‡∏±‡∏ö',
            '‡∏Ñ‡∏≤‡πÄ‡∏™‡∏ô‡∏≠': '‡∏Ñ‡∏≥‡πÄ‡∏™‡∏ô‡∏≠',
            '‡∏Ñ‡∏≤‡πÅ‡∏õ‡∏•': '‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•',

            # ===== ‡∏Ñ‡∏≥‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£‡πÄ‡∏â‡∏û‡∏≤‡∏∞ =====
            '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà: ‡∏ö‡πà': '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà: ',
            '‡∏ä‡∏≤‡∏ç.‡πÉ‡∏ô‡∏õ': '‡∏ä‡∏à‡∏ç.‡∏ô‡∏õ.',
            '‡∏û‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå': '‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå',  # OCR ‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô
            '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô ‡∏õ': '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô ‡∏ô‡∏õ.',
            '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≤‡∏á‡∏≤‡∏ô': '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô',
            '‡∏ó‡∏≤‡∏á‡∏≤‡∏ô‡∏Ø‡∏Ø': '‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ø',
            '‡∏ó‡∏≤‡∏á‡∏≤‡∏ô‡∏Ø': '‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ø',
            '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≤‡∏á‡∏≤‡∏ô‡∏Ø‡∏Ø': '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ø',
            '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≤‡∏á‡∏≤‡∏ô‡∏Ø‡∏Ø‡∏Ø': '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ø',
            '‡∏Ñ‡∏ì‡∏∞‡∏Ø‡∏Ø': '‡∏Ñ‡∏ì‡∏∞‡∏Ø',
            '‡∏Ø‡∏Ø': '‡∏Ø',
            '‡∏•‡∏ß': '‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà',
            '‡∏ô‡∏≤‡πÄ‡∏™‡∏ô‡∏≠': '‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠',
            '‡∏ô‡∏≤‡πÉ‡∏ä‡πâ': '‡∏ô‡∏≥‡πÉ‡∏ä‡πâ',
            '‡∏ô‡∏≤ AI': '‡∏ô‡∏≥ AI',
            '‡∏ô‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ': '‡∏ô‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ',
            '‡∏ô‡∏≤‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå': '‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå',
            '‡∏ô‡∏≤‡πÄ‡∏™‡∏ô‡∏≠‡∏ú‡∏•‡∏á‡∏≤‡∏ô': '‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏ú‡∏•‡∏á‡∏≤‡∏ô',
            '‡∏ô‡∏≤‡∏≠‡∏á‡∏Ñ‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ': '‡∏ô‡∏≥‡∏≠‡∏á‡∏Ñ‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ',
            '‡∏ô‡∏≤‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ': '‡∏ô‡∏≥‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ',

            # ===== ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏•‡∏±‡∏ö‡∏™‡∏£‡∏∞/‡∏ï‡∏Å‡∏´‡∏•‡πà‡∏ô =====
            '‡πÇ‡∏õ‡∏£‡∏î‡∏õ‡∏£‡∏≤‡∏ô': '‡πÇ‡∏õ‡∏£‡∏î‡∏ó‡∏£‡∏≤‡∏ö',
            '‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô ‡∏õ': '‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô ‡∏ô‡∏õ.',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡∏µ': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡πÄ‡∏ß‡∏•‡∏≤': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ß‡∏•‡∏≤',
            '‡∏Å‡∏≤‡∏´‡∏ô‡∏î‡∏ß‡∏±‡∏ô': '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡∏±‡∏ô',
            '‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏': '‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏',  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏Å‡πâ‡πÄ‡∏Å‡∏¥‡∏ô
            '‡∏Ñ‡∏≤‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà': '‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà',
            '‡∏ö‡∏ó‡∏ô‡∏≤': '‡∏ö‡∏ó‡∏ô‡∏≥',
            '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≤': '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥',
            '‡∏ô‡∏≤‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á': '‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á',
            '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≤‡∏Å‡∏≤‡∏£': '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£',
            '‡∏ó‡∏≤‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°': '‡∏ó‡∏≥‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°',
            '‡∏ó‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°': '‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°',
            '‡∏ó‡∏≤‡∏Å‡∏≤‡∏£‡∏≠‡∏ö‡∏£‡∏°': '‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏≠‡∏ö‡∏£‡∏°',
            '‡∏ó‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏≥': '‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏≥',

            # ===== ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á =====
            '‡∏ß‡∏±‡∏ô ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏õ‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°': '‡∏ß‡∏±‡∏ô ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏õ‡∏µ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°',
            '‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô': '‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô',
            '‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô': '‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô',
            '‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£': '‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£',
            '‡πÇ‡∏î‡∏¢‡∏™‡∏£‡∏∏‡∏õ ‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô': '‡πÇ‡∏î‡∏¢‡∏™‡∏£‡∏∏‡∏õ ‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô',
            '‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≤‡∏á‡∏≤‡∏ô': '‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô',
            '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≤‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏≤‡∏ô': '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏≤‡∏ô',
            '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô': '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô',
            '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≤‡∏á‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô': '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô',
            '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≤‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå': '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå',
            '‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≤‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤': '‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤',
            '‡∏£‡∏∞‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢': '‡∏£‡∏∞‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢',
        }
        
        for wrong, correct in common_errors.items():
            result = result.replace(wrong, correct)
        
        # ‡πÅ‡∏Å‡πâ spacing
        result = re.sub(r'([‡∏Å-‡∏Æ])\s+([‡∏∞-‡∏π])', r'\1\2', result)
        result = re.sub(r'([‡∏±-‡∏π])\s+([‡∏Å-‡∏Æ])', r'\1\2', result)
        result = re.sub(r'\s*:\s*', ': ', result)
        result = re.sub(r' +', ' ', result)
        result = re.sub(r'\n\s*\n\s*\n+', '\n\n', result)
        
        return result.strip()


    def correct_thai_spelling(self, text):
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡πÉ‡∏ä‡πâ PyThaiNLP)
        """
        try:
            from pythainlp import spell
            from pythainlp.tokenize import word_tokenize
        except ImportError:
            print("‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyThaiNLP ‡∏Å‡πà‡∏≠‡∏ô: pip install pythainlp")
            return text

        # ‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≥‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô
        words = word_tokenize(text, engine="newmm")

        corrected_words = []
        for w in words:
            # ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÑ‡∏ó‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç, ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå
            if not re.match(r'^[‡∏Å-‡πô]+$', w):
                corrected_words.append(w)
                continue

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏û‡∏à‡∏ô‡∏≤‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡πÑ‡∏´‡∏°
            suggested = spell(w)
            if suggested and suggested[0] != w:
                corrected_words.append(suggested[0])
            else:
                corrected_words.append(w)

        corrected_text = ''.join(corrected_words)

        # ‡πÅ‡∏Å‡πâ spacing ‡∏ã‡πâ‡∏≥‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á (‡∏Å‡∏±‡∏ô‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô)
        corrected_text = re.sub(r'([‡∏Å-‡∏Æ‡∏∞-‡πå])([A-Za-z0-9])', r'\1 \2', corrected_text)
        corrected_text = re.sub(r' +', ' ', corrected_text)

        return corrected_text.strip()

    
    def extract_key_fields(self, text):
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        """
        fields = {}
        
        # ‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà
        match = re.search(r'‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà[:\s]*([^\n]+)', text)
        if match:
            fields['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà'] = match.group(1).strip()
        
        # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        match = re.search(r'‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà[:\s]*(\d+[^\n]+)', text)
        if match:
            fields['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'] = match.group(1).strip()
        
        # ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á
        match = re.search(r'‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á[:\s]*([^\n]+(?:\n(?!\s*‡πÄ‡∏£‡∏µ‡∏¢‡∏ô)[^\n]+)*)', text)
        if match:
            fields['‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á'] = match.group(1).strip()
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
        match = re.search(r'‡πÄ‡∏£‡∏µ‡∏¢‡∏ô[:\s]*([^\n]+)', text)
        if match:
            fields['‡πÄ‡∏£‡∏µ‡∏¢‡∏ô'] = match.group(1).strip()
        
        return fields
    
    def process_document(self, file_path, save_debug=True, from_pdf=False):
        """
        Pipeline ‡∏´‡∏•‡∏±‡∏Å - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á PDF ‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏û
        """
        print(f"\n{'='*60}")
        print(f"Processing: {file_path}")
        print(f"{'='*60}\n")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô PDF ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        is_pdf = file_path.lower().endswith('.pdf')
        
        if is_pdf and PDF_SUPPORT:
            # 1. ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á text ‡∏à‡∏≤‡∏Å PDF ‡∏Å‡πà‡∏≠‡∏ô
            has_text = self.check_pdf_has_text(file_path)
            
            if has_text:
                text = self.extract_text_from_pdf(file_path)
                if text:
                    cleaned = self.post_process_thai_document(text)
                    cleaned = self.correct_thai_spelling(cleaned)
                    fields = self.extract_key_fields(cleaned)
                    
                    print(f"\n{'='*60}")
                    print("RESULTS (from PDF text layer)")
                    print(f"{'='*60}\n")
                    
                    print("--- Key Fields ---")
                    for key, value in fields.items():
                        print(f"{key}: {value}")
                    
                    print("\n--- Full Text ---")
                    print(cleaned)
                    
                    return {
                        'text': cleaned,
                        'key_fields': fields,
                        'method': 'PDF text extraction',
                        'confidence': 100.0
                    }
            
            # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ text layer -> ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û
            print("‚úì No text layer found - converting to images for OCR...")
            image_paths = self.pdf_to_images(file_path, dpi=300)
            
            if not image_paths:
                print("‚úó Failed to convert PDF to images")
                return None
            
            # OCR ‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤
            all_results = []
            for img_path in image_paths:
                result = self._process_image(img_path, save_debug, high_quality=True)
                if result:
                    all_results.append(result)
            
            # ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            if all_results:
                combined_text = '\n\n--- ‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà ---\n\n'.join([r['text'] for r in all_results])
                cleaned = self.post_process_thai_document(combined_text)
                fields = self.extract_key_fields(cleaned)
                
                avg_conf = sum([r['confidence'] for r in all_results]) / len(all_results)
                
                print(f"\n{'='*60}")
                print("COMBINED RESULTS")
                print(f"{'='*60}")
                print(f"Pages processed: {len(all_results)}")
                print(f"Average confidence: {avg_conf:.2f}%")
                
                print("\n--- Key Fields ---")
                for key, value in fields.items():
                    print(f"{key}: {value}")
                
                print("\n--- Full Text ---")
                print(cleaned)
                
                return {
                    'text': cleaned,
                    'key_fields': fields,
                    'method': 'PDF OCR',
                    'confidence': avg_conf,
                    'pages': len(all_results)
                }
        
        else:
            # ‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û
            return self._process_image(file_path, save_debug, high_quality=from_pdf)
    
    def _process_image(self, image_path, save_debug, high_quality=False):
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß
        """
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å preprocessing ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
        if high_quality:
            processed = self.preprocess_for_high_quality(image_path)
        else:
            processed = self.preprocess_for_low_quality(image_path)
        
        if save_debug:
            debug_path = image_path.replace('.', '_debug.')
            cv2.imwrite(debug_path, processed)
        
        # OCR
        result = self.ocr_with_multiple_configs(processed)
        
        if not result:
            return None
        
        cleaned = self.post_process_thai_document(result['text'])
        cleaned = self.correct_thai_spelling(cleaned)
        fields = self.extract_key_fields(cleaned)
        
        return {
            'text': cleaned,
            'key_fields': fields,
            'confidence': result['confidence']
        }


# ===== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô =====

def main():
    ocr = EnhancedThaiDocumentOCR()
    
    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô path ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
    file_path = "document.pdf"  # ‡∏´‡∏£‡∏∑‡∏≠ "document.jpg"
    
    try:
        result = ocr.process_document(file_path, save_debug=True)
        
        if result:
            print(f"\n\n{'='*60}")
            print("SUCCESS!")
            print(f"{'='*60}")
            print(f"Method: {result.get('method', 'Image OCR')}")
            print(f"Confidence: {result['confidence']:.2f}%")
            
    except FileNotFoundError:
        print(f"‚úó File not found: {file_path}")
    except Exception as e:
        print(f"‚úó Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()